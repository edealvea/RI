{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "81f9118460494f35a6396eeea8d4d17b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_74c0b9a26c5d4742890db13bae034b32",
              "IPY_MODEL_9fde024d44804b1aba64d72c0d3e918f",
              "IPY_MODEL_18861fda85b94372932b5f2e7e90c9aa"
            ],
            "layout": "IPY_MODEL_95470d96ce71490fabe99e27bda4f276"
          }
        },
        "74c0b9a26c5d4742890db13bae034b32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a4d53b12aa8747a09d39ff1af305bc68",
            "placeholder": "​",
            "style": "IPY_MODEL_99a7fb1a07b24aef9ac17a09367616c2",
            "value": "doc-text.trec: "
          }
        },
        "9fde024d44804b1aba64d72c0d3e918f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb0b724deb164049962009dd414f3003",
            "max": 1035244,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0b0e2ab8590e41918d46c4fc09c14442",
            "value": 1035244
          }
        },
        "18861fda85b94372932b5f2e7e90c9aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_acc1cdcaf4fe42b2b5ec0adc557812d8",
            "placeholder": "​",
            "style": "IPY_MODEL_32b27da094c346bf8cfc88770e7c9fd6",
            "value": " 3.33M/? [00:00&lt;00:00, 10.0MiB/s]"
          }
        },
        "95470d96ce71490fabe99e27bda4f276": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4d53b12aa8747a09d39ff1af305bc68": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "99a7fb1a07b24aef9ac17a09367616c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cb0b724deb164049962009dd414f3003": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b0e2ab8590e41918d46c4fc09c14442": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "acc1cdcaf4fe42b2b5ec0adc557812d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32b27da094c346bf8cfc88770e7c9fd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ad7e7efab0824f81a40ba8a3a2af5ea2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_825426a4e3a54c59a9126130173ec4ae",
              "IPY_MODEL_18af92a9d35242d19d9f6cb4aacbe310",
              "IPY_MODEL_13e0660898454c21ac7343bf1eae8986"
            ],
            "layout": "IPY_MODEL_ea559272828b49dfab820a794513472f"
          }
        },
        "825426a4e3a54c59a9126130173ec4ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f02aa87d34df428880d9ed0864fffe16",
            "placeholder": "​",
            "style": "IPY_MODEL_4ff5aaf41f704eaf89831f41fd9d63f5",
            "value": "query-text.trec: "
          }
        },
        "18af92a9d35242d19d9f6cb4aacbe310": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fce0027ac8e94bcaad02e2910e0bf135",
            "max": 3121,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c11ccfa44ec1498ea9946a5e4291139f",
            "value": 3121
          }
        },
        "13e0660898454c21ac7343bf1eae8986": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_03c7ca6751fe405a9caac9e68bf1b27f",
            "placeholder": "​",
            "style": "IPY_MODEL_1b4ba1fd23994eb491f1bc48534fee4f",
            "value": " 10.7k/? [00:00&lt;00:00, 250kiB/s]"
          }
        },
        "ea559272828b49dfab820a794513472f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f02aa87d34df428880d9ed0864fffe16": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ff5aaf41f704eaf89831f41fd9d63f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fce0027ac8e94bcaad02e2910e0bf135": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c11ccfa44ec1498ea9946a5e4291139f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "03c7ca6751fe405a9caac9e68bf1b27f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b4ba1fd23994eb491f1bc48534fee4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6ef7ab1cb1714e2987d166bbdeae956a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b438376f4690470096870c57fd4185ce",
              "IPY_MODEL_0e475b06367f4c1fb185ffb363565f25",
              "IPY_MODEL_4506bfd99a764fc8a81efb871177eed8"
            ],
            "layout": "IPY_MODEL_68db41b5153c4c598995cb523241546c"
          }
        },
        "b438376f4690470096870c57fd4185ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_684d4256b7e241998bb4c873f5075f92",
            "placeholder": "​",
            "style": "IPY_MODEL_75053efca292424fb0e1d3a75c8d6816",
            "value": "qrels: "
          }
        },
        "0e475b06367f4c1fb185ffb363565f25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7f87bf699a8743d68750d925d9e009ee",
            "max": 6793,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_961efdbd7be14744a6a4386a61602194",
            "value": 6793
          }
        },
        "4506bfd99a764fc8a81efb871177eed8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e43fb4dc2424aa391cd6cc5dbb64d7a",
            "placeholder": "​",
            "style": "IPY_MODEL_90055ad336c34a40a661c80ef8a18d93",
            "value": " 24.3k/? [00:00&lt;00:00, 740kiB/s]"
          }
        },
        "68db41b5153c4c598995cb523241546c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "684d4256b7e241998bb4c873f5075f92": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75053efca292424fb0e1d3a75c8d6816": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7f87bf699a8743d68750d925d9e009ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "961efdbd7be14744a6a4386a61602194": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5e43fb4dc2424aa391cd6cc5dbb64d7a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90055ad336c34a40a661c80ef8a18d93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Recuperación de Información\n",
        "# Práctica 1 &mdash; Motores de búsqueda\n",
        "### Autores:\n",
        "\n",
        "Óscar Calvet \\\\\n",
        "Enrique Ernesto de Alvear"
      ],
      "metadata": {
        "id": "QKvSdfOJfYQA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Funciones de ranking no supervisado.\n",
        "\n",
        "Dada una pequeña colección \"de juguete\", calcular el ranking de búsqueda para varias consultas según las siguientes funciones de ranking no supervisado:\n",
        "\n",
        "<ol type=\"a\">\n",
        "<li> Coseno TF-IDF (modelo vectorial).\n",
        "<li> BM25.\n",
        "<li> Query likelihood.\n",
        "</ol>"
      ],
      "metadata": {
        "id": "QWsReP-mr_0c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Definir las funciones de ranking a continuación."
      ],
      "metadata": {
        "id": "lDRwNRIhjjFK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from math import sqrt, log2\n",
        "import numpy as np\n",
        "class VSM:\n",
        "  def __init__(self, freqvector, docfreqs):\n",
        "    self.freqvector = freqvector\n",
        "    self.docfreqs = docfreqs\n",
        "\n",
        "  def search(self, q):\n",
        "    # Calculamos los cosenos de todos los documentos.\n",
        "    ranking = [(url, self.dotproduct(url, q) / self.module(url)) for url in self.freqvector]\n",
        "    # Eliminamos los documentos con coseno = 0.\n",
        "    ranking = [(url, cos) for url, cos in ranking if cos > 0]\n",
        "    # Ordenamos.\n",
        "    ranking.sort(key=lambda x: x[1], reverse=True)\n",
        "    return ranking\n",
        "\n",
        "  def dotproduct(self, url, q):\n",
        "    result = 0\n",
        "    for word in q:\n",
        "      result += self.tf(word, url) * self.idf(word)\n",
        "    return result\n",
        "\n",
        "\n",
        "  def module(self, url):\n",
        "    result = 0\n",
        "    for word in self.freqvector[url]:\n",
        "      result += self.freqvector[url][word]**2\n",
        "    return sqrt(result)\n",
        "\n",
        "\n",
        "\n",
        "  def tf(self, word, url):\n",
        "    if self.freqvector[url][word] > 0:\n",
        "      return (1+log2(self.freqvector[url][word]))\n",
        "    else:\n",
        "      return 0\n",
        "\n",
        "\n",
        "  def idf(self,word):\n",
        "    return (log2(len(self.freqvector) + 0.5) / (self.docfreqs[word])+1)\n",
        "\n",
        "\n",
        "# Nota: cuando una palabra aparece en más de la mitad de la colección, resulta un score BM25 negativo.\n",
        "# Una forma de evitarlo es tomar un número mínimo de documentos como |D|, es decir usar por ejemplo\n",
        "# |D| = max(20, len(freqvector))\n",
        "\n",
        "class BM25:\n",
        "  def __init__(self, freqvector, docfreqs, b, k):\n",
        "    self.freqvector = freqvector\n",
        "    self.docfreqs = docfreqs\n",
        "    self.b = b\n",
        "    self.k = k\n",
        "    self.avg = 0\n",
        "    for d in self.freqvector:\n",
        "      self.avg += np.array(list(self.freqvector[d].values())).sum()\n",
        "    self.avg /= len(self.freqvector)\n",
        "\n",
        "\n",
        "  def search(self, q):\n",
        "    ranking = []\n",
        "\n",
        "    def RSJ(w):\n",
        "      return log2((max(20,len(self.freqvector)) - self.docfreqs[w] + 0.5) / (self.docfreqs[w] + 0.5))\n",
        "\n",
        "    def f(q, d):\n",
        "      result = 0\n",
        "      for word in q:\n",
        "        result += self.freqvector[d][word]*(self.k + 1)*RSJ(word)/(self.k*(1-self.b + self.b*np.array(list(self.freqvector[d].values())).sum()/self.avg)+ self.freqvector[d][word])\n",
        "      return result\n",
        "\n",
        "    for d in self.freqvector.keys():\n",
        "      ranking.append((d, f(q, d)))\n",
        "\n",
        "    ranking.sort(key=lambda x: x[1], reverse=True)\n",
        "    return ranking\n",
        "\n",
        "class QLD:\n",
        "  def __init__(self, freqvector, wordfreqs, mu):\n",
        "    self.freqvector = freqvector\n",
        "    self.wordfreqs = wordfreqs\n",
        "    self.mu = mu\n",
        "\n",
        "  def search(self, q):\n",
        "    ranking = []\n",
        "    def p(w):\n",
        "      result = 0\n",
        "      contador = 0\n",
        "      for d, word_frec in self.freqvector.items():\n",
        "        result += word_frec[w]\n",
        "        contador += np.array(list(word_frec.values())).sum()\n",
        "      return result/contador\n",
        "\n",
        "    def f(q, d):\n",
        "      result = 1\n",
        "      for w in q:\n",
        "        result *= (self.freqvector[d][w] + self.mu * p(w))/(np.array(list(self.freqvector[d].values())).sum() + self.mu)\n",
        "      return result\n",
        "\n",
        "    for d in self.freqvector.keys():\n",
        "      ranking.append((d, f(q, d)))\n",
        "    ranking.sort(key=lambda x: x[1], reverse=True)\n",
        "    return ranking"
      ],
      "metadata": {
        "id": "JVM_X0BK7o6V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Programa de prueba\n",
        "\n",
        "##### 1.  Colección"
      ],
      "metadata": {
        "id": "a70Natj3jeWs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from urllib.request import urlopen\n",
        "from bs4 import BeautifulSoup\n",
        "from collections import Counter\n",
        "import re\n",
        "\n",
        "# La colección: una pequeña lista de URLs web.\n",
        "urls = [\"https://en.wikipedia.org/wiki/Age_of_Enlightenment\",\n",
        "        \"https://en.wikipedia.org/wiki/Rationalism\",\n",
        "        \"https://en.wikipedia.org/wiki/Scientific_Revolution\",\n",
        "        \"https://en.wikipedia.org/wiki/French_Revolution\",\n",
        "        \"https://en.wikipedia.org/wiki/Winner%27s_curse\",\n",
        "        \"https://en.wikipedia.org/wiki/Simpson%27s_paradox\",\n",
        "        \"https://en.wikipedia.org/wiki/Friendship_paradox\",\n",
        "        \"https://en.wikipedia.org/wiki/Condorcet_paradox\",\n",
        "        \"https://en.wikipedia.org/wiki/Paradox_of_value\",\n",
        "        \"https://en.wikipedia.org/wiki/Ship_of_Theseus\"\n",
        "       ]\n",
        "\n",
        "# Leemos los documentos y quitamos las marcas HTML.\n",
        "texts = [BeautifulSoup(urlopen(url).read(), \"lxml\").text.lower() for url in urls]\n",
        "\n",
        "# Una lista ad-hoc de stopwords.\n",
        "stoplist = [\"also\", \"could\", \"p\", \"pp\", \"th\", \"however\", \"one\", \"two\", \"many\", \"i\", \"de\", \"la\", \"me\", \"my\", \"myself\", \"the\", \"we\", \"our\", \"ours\", \"ourselves\", \"you\", \"your\", \"yours\", \"yourself\", \"yourselves\", \"he\", \"him\", \"his\", \"himself\", \"she\", \"her\", \"hers\", \"herself\", \"it\", \"its\", \"itself\", \"they\", \"them\", \"their\", \"theirs\", \"themselves\", \"what\", \"which\", \"who\", \"whom\", \"this\", \"that\", \"these\", \"those\", \"am\", \"is\", \"are\", \"was\", \"were\", \"be\", \"been\", \"being\", \"have\", \"has\", \"had\", \"having\", \"do\", \"does\", \"did\", \"doing\", \"a\", \"an\", \"the\", \"and\", \"but\", \"if\", \"or\", \"because\", \"as\", \"until\", \"while\", \"of\", \"at\", \"by\", \"for\", \"with\", \"about\", \"against\", \"between\", \"into\", \"through\", \"during\", \"before\", \"after\", \"above\", \"below\", \"to\", \"from\", \"up\", \"down\", \"in\", \"out\", \"on\", \"off\", \"over\", \"under\", \"again\", \"further\", \"then\", \"once\", \"here\", \"there\", \"when\", \"where\", \"why\", \"how\", \"all\", \"any\", \"both\", \"each\", \"few\", \"more\", \"most\", \"other\", \"some\", \"such\", \"no\", \"nor\", \"not\", \"only\", \"own\", \"same\", \"so\", \"than\", \"too\", \"very\", \"s\", \"t\", \"can\", \"will\", \"just\", \"don\", \"should\", \"now\"]"
      ],
      "metadata": {
        "id": "FIUpzllgITxA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2.  Extracción y construcción de bag of words"
      ],
      "metadata": {
        "id": "gjgvKP6jBvX7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Nos abstraemos de los detalles reales de indexación, y utilizaremos un manejo muy simplificado del texto.\n",
        "\n",
        "# Vector de frecuencias para todos los documentos de la colección, usando la subclase de diccionario collections.Counter.\n",
        "# Para cada documento, separamos el texto en lista de palabras, y Counter genera un diccionario palabra:frecuencia.\n",
        "# Se construye un diccionario url -> word -> count (se denomina un \"índice forward\").\n",
        "freqvector = {url:Counter([word for word in re.findall(r\"[^\\W\\d_]+|\\d+\", text) if word not in stoplist]) for url, text in zip(urls, texts)}\n",
        "\n",
        "# Guardamos el vocabulario (el conjunto de todas las palabras que apaercen en los documentos de la colección).\n",
        "vocabulary = set()\n",
        "for word in freqvector.values(): vocabulary.update(word)\n",
        "\n",
        "# Document frequency de cada palabra del vocabulario: nº de documentos que contienen la palabra.\n",
        "docfreqs = {word:len([url for url in freqvector if word in freqvector[url]]) for word in vocabulary}\n",
        "\n",
        "# Frecuencia total para cada palabra del vocabulario: nº total de apariciones en la colección.\n",
        "wordfreqs = {word:sum([freqvector[url][word] for url in freqvector if word in freqvector[url]]) for word in vocabulary}"
      ],
      "metadata": {
        "id": "1WNhhmSFBWJ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3.  Consultas de prueba"
      ],
      "metadata": {
        "id": "NJTC-f7UB5D5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mbj96iwHr2vl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9606a58-30e7-46c8-bccd-6d2a92e4585d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "------------------------------\n",
            "Query: ['descartes', 'montesquieu']\n",
            "\n",
            "Modelo vectorial\n",
            "0.0446170285368405 https://en.wikipedia.org/wiki/Rationalism\n",
            "0.02937428899853574 https://en.wikipedia.org/wiki/Age_of_Enlightenment\n",
            "0.018109133380976798 https://en.wikipedia.org/wiki/Scientific_Revolution\n",
            "0.01715528918441345 https://en.wikipedia.org/wiki/Ship_of_Theseus\n",
            "0.011727729675312673 https://en.wikipedia.org/wiki/French_Revolution\n",
            "\n",
            "BM25\n",
            "7.948698678858268 https://en.wikipedia.org/wiki/Age_of_Enlightenment\n",
            "3.645918143325567 https://en.wikipedia.org/wiki/French_Revolution\n",
            "3.6370779842800314 https://en.wikipedia.org/wiki/Rationalism\n",
            "3.0861571954139713 https://en.wikipedia.org/wiki/Scientific_Revolution\n",
            "2.232796011063497 https://en.wikipedia.org/wiki/Ship_of_Theseus\n",
            "0.0 https://en.wikipedia.org/wiki/Winner%27s_curse\n",
            "0.0 https://en.wikipedia.org/wiki/Simpson%27s_paradox\n",
            "0.0 https://en.wikipedia.org/wiki/Friendship_paradox\n",
            "0.0 https://en.wikipedia.org/wiki/Condorcet_paradox\n",
            "0.0 https://en.wikipedia.org/wiki/Paradox_of_value\n",
            "\n",
            "Query likelihood + Dirichlet\n",
            "2.661374315356508e-07 https://en.wikipedia.org/wiki/Age_of_Enlightenment\n",
            "1.5421052485864818e-08 https://en.wikipedia.org/wiki/Rationalism\n",
            "3.587210148874994e-09 https://en.wikipedia.org/wiki/Ship_of_Theseus\n",
            "1.1144554771472104e-09 https://en.wikipedia.org/wiki/Scientific_Revolution\n",
            "1.0980219816090415e-09 https://en.wikipedia.org/wiki/Paradox_of_value\n",
            "8.343742217468401e-10 https://en.wikipedia.org/wiki/French_Revolution\n",
            "4.805561872591658e-10 https://en.wikipedia.org/wiki/Winner%27s_curse\n",
            "2.423034085570583e-10 https://en.wikipedia.org/wiki/Condorcet_paradox\n",
            "1.8846566988730116e-10 https://en.wikipedia.org/wiki/Simpson%27s_paradox\n",
            "1.7335443355314032e-10 https://en.wikipedia.org/wiki/Friendship_paradox\n",
            "\n",
            "------------------------------\n",
            "Query: ['thought', 'experiment', 'identity']\n",
            "\n",
            "Modelo vectorial\n",
            "0.19999865127509456 https://en.wikipedia.org/wiki/Ship_of_Theseus\n",
            "0.038987540450372324 https://en.wikipedia.org/wiki/Scientific_Revolution\n",
            "0.02887926103930876 https://en.wikipedia.org/wiki/Rationalism\n",
            "0.026102803321910135 https://en.wikipedia.org/wiki/Friendship_paradox\n",
            "0.02313322539899828 https://en.wikipedia.org/wiki/Paradox_of_value\n",
            "0.019526812414122748 https://en.wikipedia.org/wiki/Age_of_Enlightenment\n",
            "0.016051328377729473 https://en.wikipedia.org/wiki/French_Revolution\n",
            "\n",
            "BM25\n",
            "8.388285471102703 https://en.wikipedia.org/wiki/Ship_of_Theseus\n",
            "6.347627331300197 https://en.wikipedia.org/wiki/Scientific_Revolution\n",
            "4.447421017997634 https://en.wikipedia.org/wiki/Age_of_Enlightenment\n",
            "4.384901630394803 https://en.wikipedia.org/wiki/Friendship_paradox\n",
            "3.6017420543226084 https://en.wikipedia.org/wiki/French_Revolution\n",
            "2.139603527601407 https://en.wikipedia.org/wiki/Rationalism\n",
            "1.4639003641060426 https://en.wikipedia.org/wiki/Paradox_of_value\n",
            "0.0 https://en.wikipedia.org/wiki/Winner%27s_curse\n",
            "0.0 https://en.wikipedia.org/wiki/Simpson%27s_paradox\n",
            "0.0 https://en.wikipedia.org/wiki/Condorcet_paradox\n",
            "\n",
            "Query likelihood + Dirichlet\n",
            "6.043682235420519e-08 https://en.wikipedia.org/wiki/Ship_of_Theseus\n",
            "3.924101916782874e-11 https://en.wikipedia.org/wiki/Scientific_Revolution\n",
            "8.577941826763216e-12 https://en.wikipedia.org/wiki/Friendship_paradox\n",
            "4.881164376156652e-12 https://en.wikipedia.org/wiki/Age_of_Enlightenment\n",
            "5.259859405497765e-13 https://en.wikipedia.org/wiki/Paradox_of_value\n",
            "7.425142100374325e-14 https://en.wikipedia.org/wiki/French_Revolution\n",
            "3.4282543150538014e-14 https://en.wikipedia.org/wiki/Rationalism\n",
            "1.4347356700966215e-14 https://en.wikipedia.org/wiki/Winner%27s_curse\n",
            "5.136826781952568e-15 https://en.wikipedia.org/wiki/Condorcet_paradox\n",
            "3.5237412838948545e-15 https://en.wikipedia.org/wiki/Simpson%27s_paradox\n",
            "\n",
            "------------------------------\n",
            "Query: ['market', 'paradox']\n",
            "\n",
            "Modelo vectorial\n",
            "0.15134924987621218 https://en.wikipedia.org/wiki/Paradox_of_value\n",
            "0.07606724405112486 https://en.wikipedia.org/wiki/Winner%27s_curse\n",
            "0.06311392133472726 https://en.wikipedia.org/wiki/Simpson%27s_paradox\n",
            "0.054428096772116866 https://en.wikipedia.org/wiki/Condorcet_paradox\n",
            "0.05329858647219133 https://en.wikipedia.org/wiki/Ship_of_Theseus\n",
            "0.04143116635585372 https://en.wikipedia.org/wiki/Friendship_paradox\n",
            "0.015596193464350039 https://en.wikipedia.org/wiki/Age_of_Enlightenment\n",
            "0.011080740709736948 https://en.wikipedia.org/wiki/Rationalism\n",
            "0.008351389753478673 https://en.wikipedia.org/wiki/Scientific_Revolution\n",
            "0.002824399613645323 https://en.wikipedia.org/wiki/French_Revolution\n",
            "\n",
            "BM25\n",
            "3.0825754702018235 https://en.wikipedia.org/wiki/Winner%27s_curse\n",
            "2.916605958707669 https://en.wikipedia.org/wiki/Age_of_Enlightenment\n",
            "2.8481025466624827 https://en.wikipedia.org/wiki/Paradox_of_value\n",
            "1.5471757445256784 https://en.wikipedia.org/wiki/Scientific_Revolution\n",
            "1.0863387676297396 https://en.wikipedia.org/wiki/French_Revolution\n",
            "0.545242203472795 https://en.wikipedia.org/wiki/Simpson%27s_paradox\n",
            "0.5432149485655469 https://en.wikipedia.org/wiki/Condorcet_paradox\n",
            "0.5391945779288885 https://en.wikipedia.org/wiki/Friendship_paradox\n",
            "0.5125945903207523 https://en.wikipedia.org/wiki/Ship_of_Theseus\n",
            "0.36946126725435635 https://en.wikipedia.org/wiki/Rationalism\n",
            "\n",
            "Query likelihood + Dirichlet\n",
            "2.455168858174535e-05 https://en.wikipedia.org/wiki/Paradox_of_value\n",
            "2.8710237114376813e-06 https://en.wikipedia.org/wiki/Winner%27s_curse\n",
            "3.977797021247201e-07 https://en.wikipedia.org/wiki/Simpson%27s_paradox\n",
            "3.6816533894509e-07 https://en.wikipedia.org/wiki/Condorcet_paradox\n",
            "1.8369173531819324e-07 https://en.wikipedia.org/wiki/Friendship_paradox\n",
            "7.609070836900694e-08 https://en.wikipedia.org/wiki/Ship_of_Theseus\n",
            "7.009098371470252e-08 https://en.wikipedia.org/wiki/Age_of_Enlightenment\n",
            "1.2223605561623049e-08 https://en.wikipedia.org/wiki/Scientific_Revolution\n",
            "2.6782731296392506e-09 https://en.wikipedia.org/wiki/Rationalism\n",
            "1.017315940258739e-09 https://en.wikipedia.org/wiki/French_Revolution\n"
          ]
        }
      ],
      "source": [
        "# Probamos tres consultas.\n",
        "for q in [['descartes', 'montesquieu'], ['thought', 'experiment', 'identity'], ['market', 'paradox']]:\n",
        "  print('\\n------------------------------')\n",
        "  print('Query:', q)\n",
        "  print('\\nModelo vectorial')\n",
        "  for url, score in VSM(freqvector, docfreqs).search(q):\n",
        "    print(score, url)\n",
        "  print('\\nBM25')\n",
        "  for url, score in BM25(freqvector, docfreqs,  b=0.5, k=1).search(q):\n",
        "    print(score, url)\n",
        "  print('\\nQuery likelihood + Dirichlet')\n",
        "  for url, score in QLD(freqvector, wordfreqs, mu=100).search(q):#Se podría tunear el mu para cambiar la importancia de que aparezca una palabra en los documentos\n",
        "    print(score, url)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Búsqueda con funciones no supervisadas implementadas en la librería PyTerrier."
      ],
      "metadata": {
        "id": "0wVORInbUuy-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Utlizamos la librería de motor de búsqueda PyTerrier.\n",
        "!pip install python-terrier\n",
        "!pip install ir-measures\n",
        "\n",
        "import pyterrier as pt\n",
        "from pyterrier.measures import *\n",
        "if not pt.started(): pt.init()\n",
        "pt.logging('ERROR')"
      ],
      "metadata": {
        "id": "MqOJP9nUhHOF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9cbfc622-0207-4f97-a1a8-3f8333c2f7af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-terrier\n",
            "  Downloading python-terrier-0.10.0.tar.gz (107 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.6/107.6 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from python-terrier) (1.25.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from python-terrier) (1.5.3)\n",
            "Collecting wget (from python-terrier)\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from python-terrier) (4.66.2)\n",
            "Collecting pyjnius>=1.4.2 (from python-terrier)\n",
            "  Downloading pyjnius-1.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting matchpy (from python-terrier)\n",
            "  Downloading matchpy-0.5.5-py3-none-any.whl (69 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.6/69.6 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from python-terrier) (1.2.2)\n",
            "Collecting deprecated (from python-terrier)\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Collecting chest (from python-terrier)\n",
            "  Downloading chest-0.2.3.tar.gz (9.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from python-terrier) (1.11.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from python-terrier) (2.31.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from python-terrier) (1.3.2)\n",
            "Collecting nptyping==1.4.4 (from python-terrier)\n",
            "  Downloading nptyping-1.4.4-py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: more_itertools in /usr/local/lib/python3.10/dist-packages (from python-terrier) (10.1.0)\n",
            "Collecting ir_datasets>=0.3.2 (from python-terrier)\n",
            "  Downloading ir_datasets-0.5.6-py3-none-any.whl (335 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m335.2/335.2 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from python-terrier) (3.1.3)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.10/dist-packages (from python-terrier) (0.14.1)\n",
            "Collecting ir_measures>=0.3.1 (from python-terrier)\n",
            "  Downloading ir_measures-0.3.3.tar.gz (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.8/48.8 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting dill (from python-terrier)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pytrec_eval_terrier>=0.5.3 (from python-terrier)\n",
            "  Downloading pytrec_eval_terrier-0.5.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (287 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m287.4/287.4 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typish>=1.7.0 (from nptyping==1.4.4->python-terrier)\n",
            "  Downloading typish-1.9.3-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.1/45.1 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: beautifulsoup4>=4.4.1 in /usr/local/lib/python3.10/dist-packages (from ir_datasets>=0.3.2->python-terrier) (4.12.3)\n",
            "Collecting inscriptis>=2.2.0 (from ir_datasets>=0.3.2->python-terrier)\n",
            "  Downloading inscriptis-2.4.0.1-py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: lxml>=4.5.2 in /usr/local/lib/python3.10/dist-packages (from ir_datasets>=0.3.2->python-terrier) (4.9.4)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ir_datasets>=0.3.2->python-terrier) (6.0.1)\n",
            "Collecting trec-car-tools>=2.5.4 (from ir_datasets>=0.3.2->python-terrier)\n",
            "  Downloading trec_car_tools-2.6-py3-none-any.whl (8.4 kB)\n",
            "Collecting lz4>=3.1.10 (from ir_datasets>=0.3.2->python-terrier)\n",
            "  Downloading lz4-4.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting warc3-wet>=0.2.3 (from ir_datasets>=0.3.2->python-terrier)\n",
            "  Downloading warc3_wet-0.2.3-py3-none-any.whl (13 kB)\n",
            "Collecting warc3-wet-clueweb09>=0.2.5 (from ir_datasets>=0.3.2->python-terrier)\n",
            "  Downloading warc3-wet-clueweb09-0.2.5.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting zlib-state>=0.1.3 (from ir_datasets>=0.3.2->python-terrier)\n",
            "  Downloading zlib-state-0.1.6.tar.gz (9.5 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting ijson>=3.1.3 (from ir_datasets>=0.3.2->python-terrier)\n",
            "  Downloading ijson-3.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (111 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.8/111.8 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyautocorpus>=0.1.1 (from ir_datasets>=0.3.2->python-terrier)\n",
            "  Downloading pyautocorpus-0.1.12-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (379 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m379.9/379.9 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting unlzw3>=0.2.1 (from ir_datasets>=0.3.2->python-terrier)\n",
            "  Downloading unlzw3-0.2.2-py3-none-any.whl (6.1 kB)\n",
            "Collecting cwl-eval>=1.0.10 (from ir_measures>=0.3.1->python-terrier)\n",
            "  Downloading cwl-eval-1.0.12.tar.gz (31 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->python-terrier) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->python-terrier) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->python-terrier) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->python-terrier) (2024.2.2)\n",
            "Collecting heapdict (from chest->python-terrier)\n",
            "  Downloading HeapDict-1.0.1-py3-none-any.whl (3.9 kB)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated->python-terrier) (1.14.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->python-terrier) (2.1.5)\n",
            "Collecting multiset<3.0,>=2.0 (from matchpy->python-terrier)\n",
            "  Downloading multiset-2.1.1-py2.py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->python-terrier) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->python-terrier) (2023.4)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->python-terrier) (3.2.0)\n",
            "Requirement already satisfied: patsy>=0.5.4 in /usr/local/lib/python3.10/dist-packages (from statsmodels->python-terrier) (0.5.6)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from statsmodels->python-terrier) (23.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4>=4.4.1->ir_datasets>=0.3.2->python-terrier) (2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy>=0.5.4->statsmodels->python-terrier) (1.16.0)\n",
            "Collecting cbor>=1.0.0 (from trec-car-tools>=2.5.4->ir_datasets>=0.3.2->python-terrier)\n",
            "  Downloading cbor-1.0.0.tar.gz (20 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: python-terrier, ir_measures, chest, wget, cwl-eval, warc3-wet-clueweb09, zlib-state, cbor\n",
            "  Building wheel for python-terrier (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-terrier: filename=python_terrier-0.10.0-py3-none-any.whl size=115532 sha256=aadd18aebb7d260c5fc1c2ab3fdac5549302f23103c9f4ee580a1056de1d419e\n",
            "  Stored in directory: /root/.cache/pip/wheels/79/7c/8f/679a982895c53af35178eceda648a4bc9a9af6af5542e31a0e\n",
            "  Building wheel for ir_measures (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ir_measures: filename=ir_measures-0.3.3-py3-none-any.whl size=61182 sha256=74680dfa40b3187d1e5055109f58d4678bf05fc4124625364829d4e7a7ebae29\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/0e/22/718279f23fef1673a4c5e433881c25080a6afaa147e007183e\n",
            "  Building wheel for chest (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for chest: filename=chest-0.2.3-py3-none-any.whl size=7612 sha256=bd86a3b2cbe3122c72fc0e2dea9ecee05f09c15a9221bbefa6946bcc6eef37e4\n",
            "  Stored in directory: /root/.cache/pip/wheels/88/cf/99/4773b31f855f9ecedc32a0ae400f7a4a3001b37c439b6d1a73\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9655 sha256=954ba017934c1cdcd30d64439adb79dafe77fc6fd35dc87faea46fc4753898c0\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/f1/7f/5c94f0a7a505ca1c81cd1d9208ae2064675d97582078e6c769\n",
            "  Building wheel for cwl-eval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cwl-eval: filename=cwl_eval-1.0.12-py3-none-any.whl size=38068 sha256=bebe446d118bd284fbd67717911fb1b3ac8ab4c4ccb2742642277ae0b287be33\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/c1/94/94a3e5379b1aa8fb7c7f1ad1956305d5edc98ef745b6067d87\n",
            "  Building wheel for warc3-wet-clueweb09 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for warc3-wet-clueweb09: filename=warc3_wet_clueweb09-0.2.5-py3-none-any.whl size=18919 sha256=b2bb38cc87b0225d389decc22b394f2d6ec336a90863ec0bbf459923f650d64c\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/d7/91/7ffb991df87e62355d945745035470ba2616aa3d83a250b5f9\n",
            "  Building wheel for zlib-state (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for zlib-state: filename=zlib_state-0.1.6-cp310-cp310-linux_x86_64.whl size=21161 sha256=8d36a8d9f62b3c64ebf7c75e06e0495c6bcfc2abe0b3d607a3efaf9732760780\n",
            "  Stored in directory: /root/.cache/pip/wheels/32/72/7e/aff80f26e926b6e1fb08dfb52aba03c0e058f5e2258deb50a9\n",
            "  Building wheel for cbor (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cbor: filename=cbor-1.0.0-cp310-cp310-linux_x86_64.whl size=53432 sha256=6bda2914825fc2edf761bcec20af0a915da4ebf95ac2a7af0c845c5785b6f9f9\n",
            "  Stored in directory: /root/.cache/pip/wheels/85/df/c9/b39e40eccaf76dbd218556639a6dc81562226f4c6a64902c85\n",
            "Successfully built python-terrier ir_measures chest wget cwl-eval warc3-wet-clueweb09 zlib-state cbor\n",
            "Installing collected packages: wget, warc3-wet-clueweb09, warc3-wet, typish, pyjnius, multiset, ijson, heapdict, cbor, zlib-state, unlzw3, trec-car-tools, pytrec_eval_terrier, pyautocorpus, nptyping, matchpy, lz4, dill, deprecated, cwl-eval, chest, ir_measures, inscriptis, ir_datasets, python-terrier\n",
            "Successfully installed cbor-1.0.0 chest-0.2.3 cwl-eval-1.0.12 deprecated-1.2.14 dill-0.3.8 heapdict-1.0.1 ijson-3.2.3 inscriptis-2.4.0.1 ir_datasets-0.5.6 ir_measures-0.3.3 lz4-4.3.3 matchpy-0.5.5 multiset-2.1.1 nptyping-1.4.4 pyautocorpus-0.1.12 pyjnius-1.6.1 python-terrier-0.10.0 pytrec_eval_terrier-0.5.6 trec-car-tools-2.6 typish-1.9.3 unlzw3-0.2.2 warc3-wet-0.2.3 warc3-wet-clueweb09-0.2.5 wget-3.2 zlib-state-0.1.6\n",
            "Requirement already satisfied: ir-measures in /usr/local/lib/python3.10/dist-packages (0.3.3)\n",
            "Requirement already satisfied: pytrec-eval-terrier>=0.5.5 in /usr/local/lib/python3.10/dist-packages (from ir-measures) (0.5.6)\n",
            "Requirement already satisfied: cwl-eval>=1.0.10 in /usr/local/lib/python3.10/dist-packages (from ir-measures) (1.0.12)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from cwl-eval>=1.0.10->ir-measures) (1.25.2)\n",
            "terrier-assemblies 5.8 jar-with-dependencies not found, downloading to /root/.pyterrier...\n",
            "Done\n",
            "terrier-python-helper 0.0.8 jar not found, downloading to /root/.pyterrier...\n",
            "Done\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "PyTerrier 0.10.0 has loaded Terrier 5.8 (built by craigm on 2023-11-01 18:05) and terrier-helper 0.0.8\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ejemplo"
      ],
      "metadata": {
        "id": "uLyhiFGjkK1F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def printsearch(name, model, q):\n",
        "  print('\\n' + name)\n",
        "  # Eliminamos todas las columnas del dataframe menos score y docno\n",
        "  print((model).search(q)[['score', 'docno']].to_string(index=False))\n",
        "\n",
        "def eval(names, models, queries, qrels, metrics, sort=[], baseline=None):\n",
        "  # La clase Experiment ejecuta rankers sobre una batería de consultas, y calcula métricas.\n",
        "  # El parámetro \"baseline\" hace que se añadan p-valores (y nº de consultas ganadas/perdidad) respecto a uno de los rankers.\n",
        "  # Con el parámetro \"sort\" se ordena la tabla de métricas la métrica que se indique.\n",
        "  print(pt.Experiment(models, queries, qrels, metrics, names, baseline=baseline).sort_values(str(sort), ascending=False).to_string(index=False))\n",
        "\n",
        "# Accedemos a una colección \"Vaswani\" ya construida e indexada en PyTerrier.\n",
        "dataset = pt.get_dataset('vaswani')\n",
        "# index = pt.IndexFactory.of(dataset.get_index())\n",
        "index = pt.IndexFactory.of(pt.IterDictIndexer('./index').index(pt.get_dataset('vaswani').get_corpus_iter()))\n",
        "queries = dataset.get_topics()\n",
        "qrels = dataset.get_qrels()\n",
        "\n",
        "# Sacamos una consulta cualquiera del conjunto de datos para probar los rankers.\n",
        "q = queries[queries.qid=='5']['query'].values[0]\n",
        "\n",
        "# Creamos y probamos rankers no supervisados por VSM, BM25, QLD y otros.\n",
        "vsm = pt.BatchRetrieve(index, wmodel='TF_IDF')\n",
        "bm25 = pt.BatchRetrieve(index, wmodel='BM25')\n",
        "qld = pt.BatchRetrieve(index, wmodel='DirichletLM')\n",
        "pl2 = pt.BatchRetrieve(index, wmodel='PL2')\n",
        "dph = pt.BatchRetrieve(index, wmodel='DPH')\n",
        "print('Query:', q)\n",
        "# El operador \"%n\" de PyTerrier pide al modelo que produzca sólo el top n del ranking.\n",
        "printsearch('Modelo vectorial', vsm%10, q)\n",
        "printsearch('BM25', bm25%10, q)\n",
        "printsearch('Query likelihood Dirichlet', qld%10, q)\n",
        "\n",
        "# Calculamos varias métricas\n",
        "eval(['Modelo vectorial', 'BM25', 'Query likelihood Dirichlet', 'DFR Poisson Laplace', 'DFR DPH'],\n",
        "     [vsm%50, bm25%50, qld%50, pl2%50, dph%50],\n",
        "     queries, qrels, [P@10, nDCG, nDCG@10, RR], baseline=0, sort=nDCG@10)"
      ],
      "metadata": {
        "id": "vOqgsiETU1sz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 964,
          "referenced_widgets": [
            "81f9118460494f35a6396eeea8d4d17b",
            "74c0b9a26c5d4742890db13bae034b32",
            "9fde024d44804b1aba64d72c0d3e918f",
            "18861fda85b94372932b5f2e7e90c9aa",
            "95470d96ce71490fabe99e27bda4f276",
            "a4d53b12aa8747a09d39ff1af305bc68",
            "99a7fb1a07b24aef9ac17a09367616c2",
            "cb0b724deb164049962009dd414f3003",
            "0b0e2ab8590e41918d46c4fc09c14442",
            "acc1cdcaf4fe42b2b5ec0adc557812d8",
            "32b27da094c346bf8cfc88770e7c9fd6",
            "ad7e7efab0824f81a40ba8a3a2af5ea2",
            "825426a4e3a54c59a9126130173ec4ae",
            "18af92a9d35242d19d9f6cb4aacbe310",
            "13e0660898454c21ac7343bf1eae8986",
            "ea559272828b49dfab820a794513472f",
            "f02aa87d34df428880d9ed0864fffe16",
            "4ff5aaf41f704eaf89831f41fd9d63f5",
            "fce0027ac8e94bcaad02e2910e0bf135",
            "c11ccfa44ec1498ea9946a5e4291139f",
            "03c7ca6751fe405a9caac9e68bf1b27f",
            "1b4ba1fd23994eb491f1bc48534fee4f",
            "6ef7ab1cb1714e2987d166bbdeae956a",
            "b438376f4690470096870c57fd4185ce",
            "0e475b06367f4c1fb185ffb363565f25",
            "4506bfd99a764fc8a81efb871177eed8",
            "68db41b5153c4c598995cb523241546c",
            "684d4256b7e241998bb4c873f5075f92",
            "75053efca292424fb0e1d3a75c8d6816",
            "7f87bf699a8743d68750d925d9e009ee",
            "961efdbd7be14744a6a4386a61602194",
            "5e43fb4dc2424aa391cd6cc5dbb64d7a",
            "90055ad336c34a40a661c80ef8a18d93"
          ]
        },
        "outputId": "255468a2-fb46-4dfc-8132-eb4ce5ad9434"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading vaswani corpus to /root/.pyterrier/corpora/vaswani/corpus\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "doc-text.trec:   0%|          | 0.00/0.99M [00:00<?, ?iB/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "81f9118460494f35a6396eeea8d4d17b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading vaswani topics to /root/.pyterrier/corpora/vaswani/query-text.trec\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "query-text.trec:   0%|          | 0.00/3.05k [00:00<?, ?iB/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ad7e7efab0824f81a40ba8a3a2af5ea2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading vaswani qrels to /root/.pyterrier/corpora/vaswani/qrels\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "qrels:   0%|          | 0.00/6.63k [00:00<?, ?iB/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6ef7ab1cb1714e2987d166bbdeae956a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: use of programs in engineering testing of computers\n",
            "\n",
            "Modelo vectorial\n",
            "    score docno\n",
            "14.442821  1586\n",
            "12.833733 11429\n",
            "10.506225  7875\n",
            " 9.889541  3559\n",
            " 9.809790  2290\n",
            " 9.737880  5130\n",
            " 9.486759  4307\n",
            " 9.451995  4308\n",
            " 9.403773  9165\n",
            " 9.344073 10156\n",
            "\n",
            "BM25\n",
            "    score docno\n",
            "26.192890  1586\n",
            "23.252472 11429\n",
            "18.996809  7875\n",
            "18.066157  3559\n",
            "17.749907  2290\n",
            "17.594194  5130\n",
            "17.129366  4307\n",
            "17.090606  4308\n",
            "17.045979  9165\n",
            "16.895468 10156\n",
            "\n",
            "Query likelihood Dirichlet\n",
            "   score docno\n",
            "3.305896  1586\n",
            "3.287824  2373\n",
            "3.002635 11429\n",
            "2.937968  3559\n",
            "2.570817  4307\n",
            "2.495430  4709\n",
            "2.434525   276\n",
            "2.379995  5538\n",
            "2.292910  7875\n",
            "2.283731  4308\n",
            "                      name       RR     P@10     nDCG  nDCG@10  RR +  RR -  RR p-value  P@10 +  P@10 -  P@10 p-value  nDCG +  nDCG -  nDCG p-value  nDCG@10 +  nDCG@10 -  nDCG@10 p-value\n",
            "                      BM25 0.725126 0.352688 0.442753 0.446609  13.0   3.0    0.026092     2.0     8.0  5.734926e-02    38.0    41.0  2.942729e-01       16.0       23.0     6.300102e-01\n",
            "          Modelo vectorial 0.698671 0.359140 0.438444 0.444411   NaN   NaN         NaN     NaN     NaN           NaN     NaN     NaN           NaN        NaN        NaN              NaN\n",
            "                   DFR DPH 0.688162 0.358065 0.430284 0.434968  16.0  17.0    0.642894    20.0    19.0  9.075744e-01    42.0    44.0  3.519212e-01       39.0       40.0     4.088487e-01\n",
            "       DFR Poisson Laplace 0.681855 0.338710 0.421514 0.424514  11.0  10.0    0.253856     4.0    19.0  1.038967e-03    17.0    69.0  8.536018e-04       21.0       46.0     3.651326e-03\n",
            "Query likelihood Dirichlet 0.553555 0.239785 0.319684 0.297378  16.0  38.0    0.000521    10.0    60.0  6.696039e-10    21.0    70.0  4.312717e-10       18.0       67.0     3.753995e-09\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ejercicio: probar más modelos no supervisados y métricas de PyTerrier\n",
        "\n",
        "La lista completa de rankers de PyTerrier está disponible en http://terrier.org/docs/current/javadoc/org/terrier/matching/models/package-summary.html.\n",
        "\n",
        "La lista de métricas en https://pyterrier.readthedocs.io/en/latest/experiments.html."
      ],
      "metadata": {
        "id": "m_-Ooi6ckTA1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hemos probado los modelos BB2, DFR_BM25, DFRee, DLH13, IFB2 y hemos añadido las métricas MAP (Mean Average Precision), la precisión para los 5 primeros resultados (P@5), el normalized Discounted Cumulative Gain para los 5 primeros resultados (nDCG@5), el recall para los 10 primeros (R@10), el recall para los 5 primeros (R@5) y el número de documentos relevantes recuperados (NumRelRet)"
      ],
      "metadata": {
        "id": "FBJzNqV_rzQL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bb2 = pt.BatchRetrieve(index, wmodel='BB2')\n",
        "dfr_bm25 = pt.BatchRetrieve(index, wmodel='DFR_BM25')\n",
        "dfree = pt.BatchRetrieve(index, wmodel = 'DFRee')\n",
        "dlh13 = pt.BatchRetrieve(index, wmodel = 'DLH13')\n",
        "ifb2 = pt.BatchRetrieve(index, wmodel = 'IFB2')\n",
        "\n",
        "eval(['Modelo vectorial', 'BM25', 'Query likelihood Dirichlet', 'DFR Poisson Laplace', 'DFR DPH'\n",
        "      ,'BB2', 'DFR_BM25', 'DFRee', 'DLH13', 'IFB2'],\n",
        "     [vsm%50, bm25%50, qld%50, pl2%50, dph%50, bb2%50, dfr_bm25%50, dfree%50, dlh13%50, ifb2%50],\n",
        "     queries, qrels, [P@10, nDCG, nDCG@10, RR, AP, NumRelRet,R@10, R@5], baseline=0, sort=nDCG@10)"
      ],
      "metadata": {
        "id": "aFXD2JU_kUgb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c39abe8c-e604-46f7-b4d4-3499a5c059a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                      name  NumRet(rel=1)       AP       RR     P@10      R@5     R@10     nDCG  nDCG@10  NumRet(rel=1) +  NumRet(rel=1) -  NumRet(rel=1) p-value  AP +  AP -   AP p-value  RR +  RR -  RR p-value  P@10 +  P@10 -  P@10 p-value  R@5 +  R@5 -  R@5 p-value  R@10 +  R@10 -  R@10 p-value  nDCG +  nDCG -  nDCG p-value  nDCG@10 +  nDCG@10 -  nDCG@10 p-value\n",
            "                       BB2       9.709677 0.254397 0.716245 0.380645 0.162723 0.226286 0.450609 0.463713             30.0             12.0           4.336078e-03  59.0  25.0 7.814678e-04  12.0   9.0    0.272563    23.0     6.0  2.154786e-03   13.0   10.0 9.377337e-01    23.0     6.0      0.218458    60.0    24.0  8.166929e-03       44.0       24.0     1.960054e-03\n",
            "                      IFB2       9.559140 0.253610 0.708480 0.376344 0.165677 0.223418 0.448382 0.458562             24.0             14.0           3.898300e-02  56.0  28.0 1.687820e-04  12.0   7.0    0.520833    19.0     6.0  1.064146e-02    9.0   10.0 4.461871e-01    19.0     6.0      0.537412    51.0    33.0  5.936219e-03       41.0       24.0     1.365086e-02\n",
            "                     DLH13       9.344086 0.239991 0.698714 0.373118 0.156629 0.224333 0.433643 0.452133             25.0             25.0           7.755778e-01  44.0  41.0 5.656490e-01  13.0  13.0    0.997824    25.0    15.0  1.234935e-01   12.0   21.0 3.418249e-01    25.0    15.0      0.467979    40.0    45.0  3.601101e-01       38.0       35.0     3.418118e-01\n",
            "                  DFR_BM25       9.290323 0.246857 0.723426 0.355914 0.163849 0.220328 0.442731 0.447390              9.0             13.0           7.336079e-01  42.0  41.0 2.332435e-01  12.0   4.0    0.035706     4.0     7.0  3.685456e-01    3.0    8.0 6.974983e-01     4.0     7.0      0.911179    42.0    41.0  3.214311e-01       17.0       25.0     4.715378e-01\n",
            "                      BM25       9.268817 0.247820 0.725126 0.352688 0.162592 0.218513 0.442753 0.446609              9.0             14.0           4.824717e-01  39.0  40.0 2.468742e-01  13.0   3.0    0.026092     2.0     8.0  5.734926e-02    2.0    8.0 9.468261e-01     2.0     8.0      0.324885    38.0    41.0  2.942729e-01       16.0       23.0     6.300102e-01\n",
            "          Modelo vectorial       9.311828 0.242337 0.698671 0.359140 0.162330 0.220588 0.438444 0.444411              NaN              NaN                    NaN   NaN   NaN          NaN   NaN   NaN         NaN     NaN     NaN           NaN    NaN    NaN          NaN     NaN     NaN           NaN     NaN     NaN           NaN        NaN        NaN              NaN\n",
            "                   DFR DPH       9.333333 0.232489 0.688162 0.358065 0.149907 0.214512 0.430284 0.434968             30.0             29.0           9.155483e-01  40.0  46.0 2.018153e-01  16.0  17.0    0.642894    20.0    19.0  9.075744e-01   16.0   27.0 1.083755e-01    20.0    19.0      0.438592    42.0    44.0  3.519212e-01       39.0       40.0     4.088487e-01\n",
            "                     DFRee       9.279570 0.231888 0.696346 0.356989 0.144575 0.211797 0.426506 0.434793             27.0             29.0           8.880636e-01  46.0  40.0 1.884947e-01  16.0  15.0    0.918382    21.0    27.0  8.457455e-01   17.0   31.0 2.250146e-02    21.0    27.0      0.269208    43.0    43.0  2.015557e-01       37.0       41.0     4.408858e-01\n",
            "       DFR Poisson Laplace       8.881720 0.229606 0.681855 0.338710 0.156927 0.213560 0.421514 0.424514              2.0             31.0           1.794115e-06  17.0  69.0 2.219594e-02  11.0  10.0    0.253856     4.0    19.0  1.038967e-03    2.0   14.0 2.754360e-01     4.0    19.0      0.013363    17.0    69.0  8.536018e-04       21.0       46.0     3.651326e-03\n",
            "Query likelihood Dirichlet       7.032258 0.149271 0.553555 0.239785 0.092045 0.153779 0.319684 0.297378             16.0             63.0           2.295686e-09  19.0  72.0 7.044946e-09  16.0  38.0    0.000521    10.0    60.0  6.696039e-10    5.0   58.0 2.026645e-08    10.0    60.0      0.000366    21.0    70.0  4.312717e-10       18.0       67.0     3.753995e-09\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Learning to rank con características de texto."
      ],
      "metadata": {
        "id": "ArwkVzxAjOvm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ejemplo"
      ],
      "metadata": {
        "id": "xR_zT_d4pjif"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import lightgbm as lgb\n",
        "\n",
        "# Definimos el vector de características, e indicamos la función de ranking para el primer filtro de candidatos \"first stage ranking\".\n",
        "fsr = pt.FeaturesBatchRetrieve(index, controls = {'wmodel': 'BM25'}, features=['SAMPLE', 'WMODEL:DirichletLM', 'WMODEL:PL2'])\n",
        "\n",
        "# Vamos a usar el modelo GBDT LambdaMART implementado en LightGBM.\n",
        "# Configuramos el modelo.\n",
        "lmart = lgb.LGBMRanker(\n",
        "    task='train',\n",
        "    min_data_in_leaf=2,\n",
        "    max_depth=4,\n",
        "    num_leaves=2**4,\n",
        "    objective='lambdarank',\n",
        "    metric='ndcg',\n",
        "    importance_type='gain',\n",
        "    reg_lambda=0.01,\n",
        "    n_estimators=10,\n",
        "    verbose=-1,\n",
        "    random_state=0 # For reproducibility\n",
        "    )\n",
        "\n",
        "# Enganchamos al modelo la salida del filtro de candidatos con su vector de características a utilizar\n",
        "# en el modelo supervisado.\n",
        "ltr = fsr >> pt.ltr.apply_learned_model(lmart, form='ltr')\n",
        "\n",
        "# Particionamos los datos (las consultas) en entrenamiento (60%), validación (20%) y test (20%).\n",
        "np.random.seed(0) # For reproducibility\n",
        "train, validation, test = np.split(queries, [int(.6*len(queries)), int(.8*len(queries))])\n",
        "\n",
        "# Entrenamos el modelo usando los juicios de relevancia (qrels). Aunque los qrels incluyen los datos de\n",
        "# test, la función fit sólo utiliza los juicios asociados a las consultas de entrenamiento y validación.\n",
        "ltr.fit(train, qrels, validation, qrels)\n",
        "\n",
        "# Ejecutamos el modelo entrenado sobre una consulta y observamos la salida.\n",
        "printsearch('BM25 + LambdaMART', ltr%10, q)\n",
        "\n",
        "# Evaluamos y comparamos.\n",
        "eval(['Modelo vectorial', 'BM25', 'Query likelihood Dirichlet', 'DFR Poisson Laplace', 'DFR DPH', 'BM25 + LambdaMART'],\n",
        "     [vsm%50, bm25%50, qld%50, pl2%50, dph%50, ltr%50],\n",
        "     test, qrels, [P@10, nDCG, nDCG@10, RR], sort=nDCG@10, baseline=0)"
      ],
      "metadata": {
        "id": "Yqyh5xMgjT3y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e3d77c4-50b8-49cf-b1c8-ac7ca02c0bda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "BM25 + LambdaMART\n",
            "   score docno\n",
            "1.314159  1586\n",
            "0.971874 11429\n",
            "0.947643  7875\n",
            "0.947643  3559\n",
            "0.947643  2290\n",
            "0.947643  5130\n",
            "0.819120  2511\n",
            "0.819120  2927\n",
            "0.819120  2675\n",
            "0.790350  3039\n",
            "                      name       RR     P@10     nDCG  nDCG@10  RR +  RR -  RR p-value  P@10 +  P@10 -  P@10 p-value  nDCG +  nDCG -  nDCG p-value  nDCG@10 +  nDCG@10 -  nDCG@10 p-value\n",
            "                      BM25 0.595052 0.252632 0.347720 0.306262   2.0   1.0    0.606020     1.0     0.0      0.330565     7.0     8.0      0.865871        3.0        4.0         0.569843\n",
            "          Modelo vectorial 0.596739 0.247368 0.347220 0.304047   NaN   NaN         NaN     NaN     NaN           NaN     NaN     NaN           NaN        NaN        NaN              NaN\n",
            "         BM25 + LambdaMART 0.548089 0.263158 0.328672 0.297730   4.0   6.0    0.392923     6.0     2.0      0.380004     4.0    13.0      0.067863        7.0        8.0         0.716729\n",
            "       DFR Poisson Laplace 0.568381 0.242105 0.329377 0.296378   3.0   2.0    0.299321     1.0     2.0      0.577753     5.0    12.0      0.011144        6.0        4.0         0.514222\n",
            "                   DFR DPH 0.558020 0.247368 0.325935 0.288743   4.0   3.0    0.527410     5.0     4.0      1.000000     7.0    10.0      0.131491        7.0        9.0         0.538287\n",
            "Query likelihood Dirichlet 0.348071 0.168421 0.205987 0.179280   4.0  11.0    0.048660     2.0    11.0      0.007139     4.0    14.0      0.001026        3.0       14.0         0.002702\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ejercicio: variaciones en learning to rank.\n",
        "\n",
        "Explorar la configuración de parámetros de LambdaMART.\n",
        "\n",
        "Probar otros métodos learning to rank de Terrier.\n",
        "\n",
        "Opcional: probar otras características funcionales.\n",
        "\n",
        "Intentar conseguir al menos una solución que mejore a todas las del ejemplo anterior."
      ],
      "metadata": {
        "id": "vrAwwOktphqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ejemplo de características funcionales custom.\n",
        "import re\n",
        "def _features(row):\n",
        "  content = index.getMetaIndex().getItem('text', row['docid'])\n",
        "  f1 = len(content)\n",
        "  f2 = len(re.findall(r\"[^\\W\\d_]+|\\d+\", content))\n",
        "  return np.array([f1, f2])\n",
        "\n",
        "extended_fsr = bm25 >> pt.FeaturesBatchRetrieve(index, ['SAMPLE', 'WMODEL:DirichletLM', 'WMODEL:PL2']) ** pt.apply.doc_features(_features)\n",
        "extended_ltr = extended_fsr >> pt.ltr.apply_learned_model(lmart, form=\"ltr\")\n",
        "extended_ltr.fit(train, qrels, validation, qrels)\n",
        "printsearch('Extended BM25 + LambdaMART', extended_ltr%10, q)\n",
        "eval(['Extended BM25 + LambdaMART'], [extended_ltr%50], test, qrels, [P@10, nDCG, nDCG@10, RR], sort=nDCG@10)\n"
      ],
      "metadata": {
        "id": "O_UPf2onph6u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff53af9d-2f8e-42fd-f6b1-0366de55f53b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Extended BM25 + LambdaMART\n",
            "   score docno\n",
            "1.116621  1586\n",
            "1.041099 11429\n",
            "0.847516  7875\n",
            "0.822619  3559\n",
            "0.822619  2290\n",
            "0.822619  5130\n",
            "0.741470  9165\n",
            "0.683661  2511\n",
            "0.683661  2927\n",
            "0.683661  2675\n",
            "                      name     P@10     nDCG  nDCG@10       RR\n",
            "Extended BM25 + LambdaMART 0.247368 0.323922  0.28667 0.527251\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para la exploración de parámetros vamos a variar los siguientes atributos:\n",
        "- num_leaves\n",
        "- max_depth\n",
        "- n_estimators\n",
        "- learning_rate"
      ],
      "metadata": {
        "id": "ODlb1HDfPoQi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Exploración de parámetros\n",
        "# Particionamos los datos (las consultas) en entrenamiento (60%), validación (20%) y test (20%).\n",
        "np.random.seed(0) # For reproducibility\n",
        "train, validation, test = np.split(queries, [int(.6*len(queries)), int(.8*len(queries))])\n",
        "num_leaves = [2, 3, 5, 8, 13, 21, 34, 55, 89, 144, 233, 377, 610]\n",
        "names = []\n",
        "models = []\n",
        "for l in num_leaves:\n",
        "  #Comenzamos con BM25\n",
        "  fsr = pt.FeaturesBatchRetrieve(index, controls = {'wmodel': 'BM25'}, features=['SAMPLE', 'WMODEL:DirichletLM', 'WMODEL:PL2'])\n",
        "  #Modelo base\n",
        "  lmart = lgb.LGBMRanker(\n",
        "      task='train',\n",
        "      min_data_in_leaf=2,\n",
        "      max_depth=4,\n",
        "      num_leaves=l,\n",
        "      objective='lambdarank',\n",
        "      metric='ndcg',\n",
        "      importance_type='gain',\n",
        "      reg_lambda=0.01,\n",
        "      n_estimators=10,\n",
        "      verbose=-1,\n",
        "      random_state=0 # For reproducibility\n",
        "      )\n",
        "  ltr = fsr >> pt.ltr.apply_learned_model(lmart, form='ltr')\n",
        "  ltr.fit(train, qrels, validation, qrels)\n",
        "  names += ['leafs ' + str(l)]\n",
        "  models += [ltr%50]\n",
        "eval(names, models, test, qrels, [P@10, nDCG, nDCG@10, RR], sort=nDCG@10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P27o__rzN9eF",
        "outputId": "adeb7495-812d-4ae4-86ab-b98be1abb644"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     name     P@10     nDCG  nDCG@10       RR\n",
            " leafs 21 0.263158 0.328672 0.297730 0.548089\n",
            " leafs 34 0.263158 0.328672 0.297730 0.548089\n",
            " leafs 55 0.263158 0.328672 0.297730 0.548089\n",
            " leafs 89 0.263158 0.328672 0.297730 0.548089\n",
            "leafs 144 0.263158 0.328672 0.297730 0.548089\n",
            "leafs 233 0.263158 0.328672 0.297730 0.548089\n",
            "leafs 377 0.263158 0.328672 0.297730 0.548089\n",
            "leafs 610 0.263158 0.328672 0.297730 0.548089\n",
            "  leafs 3 0.263158 0.332836 0.293776 0.530117\n",
            " leafs 13 0.263158 0.329922 0.293629 0.517126\n",
            "  leafs 5 0.257895 0.327597 0.291187 0.511160\n",
            "  leafs 8 0.257895 0.319955 0.288054 0.513264\n",
            "  leafs 2 0.247368 0.297557 0.238358 0.341352\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observamos que la nDCG es bastante similar entre todos los modelos, parece ser que el número de hojas por árbol no es un parámetro que afecte mucho al rendimiento."
      ],
      "metadata": {
        "id": "kpE_CEpsgWqr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Exploración de parámetros\n",
        "# Particionamos los datos (las consultas) en entrenamiento (60%), validación (20%) y test (20%).\n",
        "np.random.seed(0) # For reproducibility\n",
        "train, validation, test = np.split(queries, [int(.6*len(queries)), int(.8*len(queries))])\n",
        "max_depth = [0, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89, 144, 233, 377, 610]\n",
        "names = []\n",
        "models = []\n",
        "for m in max_depth:\n",
        "  #Comenzamos con BM25\n",
        "  fsr = pt.FeaturesBatchRetrieve(index, controls = {'wmodel': 'BM25'}, features=['SAMPLE', 'WMODEL:DirichletLM', 'WMODEL:PL2'])\n",
        "  #Modelo base\n",
        "  lmart = lgb.LGBMRanker(\n",
        "      task='train',\n",
        "      min_data_in_leaf=2,\n",
        "      max_depth=m,\n",
        "      num_leaves=2**4,\n",
        "      objective='lambdarank',\n",
        "      metric='ndcg',\n",
        "      importance_type='gain',\n",
        "      reg_lambda=0.01,\n",
        "      n_estimators=10,\n",
        "      verbose=-1,\n",
        "      random_state=0 # For reproducibility\n",
        "      )\n",
        "  ltr = fsr >> pt.ltr.apply_learned_model(lmart, form='ltr')\n",
        "  ltr.fit(train, qrels, validation, qrels)\n",
        "  names += ['depth ' + str(m)]\n",
        "  models += [ltr%50]\n",
        "eval(names, models, test, qrels, [P@10, nDCG, nDCG@10, RR], sort=nDCG@10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pKCZ7C6Kg1dq",
        "outputId": "cbc93c32-54b0-4e5f-86f0-f649ffe21290"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     name     P@10     nDCG  nDCG@10       RR\n",
            "  depth 2 0.263158 0.327876 0.293226 0.524100\n",
            "  depth 3 0.257895 0.323235 0.288000 0.518774\n",
            "  depth 8 0.247368 0.302079 0.281040 0.499434\n",
            "  depth 0 0.236842 0.316500 0.279310 0.533117\n",
            " depth 13 0.236842 0.316500 0.279310 0.533117\n",
            " depth 21 0.236842 0.316500 0.279310 0.533117\n",
            " depth 34 0.236842 0.316500 0.279310 0.533117\n",
            " depth 55 0.236842 0.316500 0.279310 0.533117\n",
            " depth 89 0.236842 0.316500 0.279310 0.533117\n",
            "depth 144 0.236842 0.316500 0.279310 0.533117\n",
            "depth 233 0.236842 0.316500 0.279310 0.533117\n",
            "depth 377 0.236842 0.316500 0.279310 0.533117\n",
            "depth 610 0.236842 0.316500 0.279310 0.533117\n",
            "  depth 5 0.236842 0.322978 0.278434 0.543915\n",
            "  depth 1 0.247368 0.297557 0.238358 0.341352\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observamos que aumentar la profundidad de los árboles resulta detrimental para el rendimiento del modelo."
      ],
      "metadata": {
        "id": "oaBG3glziRxK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Exploración de parámetros\n",
        "# Particionamos los datos (las consultas) en entrenamiento (60%), validación (20%) y test (20%).\n",
        "np.random.seed(0) # For reproducibility\n",
        "train, validation, test = np.split(queries, [int(.6*len(queries)), int(.8*len(queries))])\n",
        "n_estimators = [20, 50, 100, 200, 500, 1000]\n",
        "names = []\n",
        "models = []\n",
        "for n in n_estimators:\n",
        "  #Comenzamos con BM25\n",
        "  fsr = pt.FeaturesBatchRetrieve(index, controls = {'wmodel': 'BM25'}, features=['SAMPLE', 'WMODEL:DirichletLM', 'WMODEL:PL2'])\n",
        "  #Modelo base\n",
        "  lmart = lgb.LGBMRanker(\n",
        "      task='train',\n",
        "      min_data_in_leaf=2,\n",
        "      max_depth=4,\n",
        "      num_leaves=2**4,\n",
        "      objective='lambdarank',\n",
        "      metric='ndcg',\n",
        "      importance_type='gain',\n",
        "      reg_lambda=0.01,\n",
        "      n_estimators=n,\n",
        "      verbose=-1,\n",
        "      random_state=0 # For reproducibility\n",
        "      )\n",
        "  ltr = fsr >> pt.ltr.apply_learned_model(lmart, form='ltr')\n",
        "  ltr.fit(train, qrels, validation, qrels)\n",
        "  names += ['n_est ' + str(n)]\n",
        "  models += [ltr%50]\n",
        "eval(names, models, test, qrels, [P@10, nDCG, nDCG@10, RR], sort=nDCG@10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "keYk26OAiYkw",
        "outputId": "2df32bc7-ecaa-4194-cd07-13849f7b9693"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      name     P@10     nDCG  nDCG@10       RR\n",
            "  n_est 20 0.257895 0.325740 0.285309 0.522974\n",
            " n_est 100 0.252632 0.315988 0.266970 0.441862\n",
            "  n_est 50 0.231579 0.315387 0.255714 0.455963\n",
            " n_est 200 0.210526 0.307483 0.240431 0.457506\n",
            " n_est 500 0.200000 0.288669 0.222714 0.425666\n",
            "n_est 1000 0.152632 0.265119 0.192050 0.437955\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aumentar los estimadores tampoco mejora notablemente el rendimiento."
      ],
      "metadata": {
        "id": "i2iszyuBjeRl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Exploración de parámetros\n",
        "# Particionamos los datos (las consultas) en entrenamiento (60%), validación (20%) y test (20%).\n",
        "np.random.seed(0) # For reproducibility\n",
        "train, validation, test = np.split(queries, [int(.6*len(queries)), int(.8*len(queries))])\n",
        "names = []\n",
        "models = []\n",
        "learning_rate = [0.01, 0.02 ,0.05, 0.1, 0.2]\n",
        "for lr in learning_rate:\n",
        "  #Comenzamos con BM25\n",
        "  fsr = pt.FeaturesBatchRetrieve(index, controls = {'wmodel': 'BM25'}, features=['SAMPLE', 'WMODEL:DirichletLM', 'WMODEL:PL2'])\n",
        "  #Modelo base\n",
        "  lmart = lgb.LGBMRanker(\n",
        "      task='train',\n",
        "      min_data_in_leaf=2,\n",
        "      max_depth=4,\n",
        "      num_leaves=2**4,\n",
        "      objective='lambdarank',\n",
        "      metric='ndcg',\n",
        "      importance_type='gain',\n",
        "      reg_lambda=0.01,\n",
        "      n_estimators=10,\n",
        "      verbose=-1,\n",
        "      learning_rate = lr,\n",
        "      random_state=0 # For reproducibility\n",
        "      )\n",
        "  ltr = fsr >> pt.ltr.apply_learned_model(lmart, form='ltr')\n",
        "  ltr.fit(train, qrels, validation, qrels)\n",
        "  names += ['lr ' + str(lr)]\n",
        "  models += [ltr%50]\n",
        "eval(names, models, test, qrels, [P@10, nDCG, nDCG@10, RR], sort=nDCG@10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FOu1HnLzjjj2",
        "outputId": "f2312963-145c-4868-bf3a-240fb541d1f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   name     P@10     nDCG  nDCG@10       RR\n",
            " lr 0.1 0.263158 0.328672 0.297730 0.548089\n",
            "lr 0.05 0.263158 0.331144 0.295564 0.524123\n",
            "lr 0.02 0.257895 0.320864 0.288798 0.519593\n",
            "lr 0.01 0.247368 0.326757 0.282578 0.516538\n",
            " lr 0.2 0.231579 0.330366 0.275283 0.521553\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Valores pequeños del learning rate parecen ser beneficiosos para mejorar el rendimiento de los modelos.\n",
        "\n",
        "Terminamos haciendo un grid de un subconjunto de todos hiperparámetros que hemos analizado."
      ],
      "metadata": {
        "id": "gptsMYtgkoyW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Exploración de parámetros\n",
        "# Particionamos los datos (las consultas) en entrenamiento (60%), validación (20%) y test (20%).\n",
        "np.random.seed(0) # For reproducibility\n",
        "train, validation, test = np.split(queries, [int(.6*len(queries)), int(.8*len(queries))])\n",
        "num_leaves = [5, 8,10]\n",
        "max_depth = [2, 3, 5]\n",
        "n_estimators = [20, 50, 100]\n",
        "learning_rate = [0.01, 0.05, 0.1]\n",
        "names = []\n",
        "models = []\n",
        "for l in num_leaves:\n",
        "  for m in max_depth:\n",
        "    for n in n_estimators:\n",
        "      for lr in learning_rate:\n",
        "        #Comenzamos con BM25\n",
        "        fsr = pt.FeaturesBatchRetrieve(index, controls = {'wmodel': 'BM25'}, features=['SAMPLE', 'WMODEL:DirichletLM', 'WMODEL:PL2'])\n",
        "        #Modelo base\n",
        "        lmart = lgb.LGBMRanker(\n",
        "            task='train',\n",
        "            min_data_in_leaf=2,\n",
        "            max_depth=m,\n",
        "            num_leaves=l,\n",
        "            objective='lambdarank',\n",
        "            metric='ndcg',\n",
        "            importance_type='gain',\n",
        "            reg_lambda=0.01,\n",
        "            n_estimators=n,\n",
        "            verbose=-1,\n",
        "            learning_rate = lr,\n",
        "            random_state=0 # For reproducibility\n",
        "            )\n",
        "        ltr = fsr >> pt.ltr.apply_learned_model(lmart, form='ltr')\n",
        "        ltr.fit(train, qrels, validation, qrels)\n",
        "        names += ['l' + str(l) + ' m' + str(m) + ' n' + str(n) + ' lr' + str(lr)]\n",
        "        models += [ltr%50]\n",
        "eval(names, models, test, qrels, [P@10, nDCG, nDCG@10, RR], sort=nDCG@10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pVXuIm0YlDD1",
        "outputId": "90ef8f90-c125-427a-fe49-e3977b93a64d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                  name     P@10     nDCG  nDCG@10       RR\n",
            "l 10 m 2 n 100 lr 0.05 0.268421 0.333629 0.310755 0.572830\n",
            " l 8 m 2 n 100 lr 0.05 0.268421 0.333629 0.310755 0.572830\n",
            " l 5 m 2 n 100 lr 0.05 0.268421 0.333629 0.310755 0.572830\n",
            "  l 10 m 2 n 50 lr 0.1 0.268421 0.330636 0.306130 0.544838\n",
            "   l 8 m 2 n 50 lr 0.1 0.268421 0.330636 0.306130 0.544838\n",
            "   l 5 m 2 n 50 lr 0.1 0.268421 0.330636 0.306130 0.544838\n",
            " l 10 m 5 n 20 lr 0.01 0.263158 0.324123 0.304445 0.593837\n",
            "  l 5 m 2 n 50 lr 0.05 0.263158 0.335012 0.301662 0.546159\n",
            "  l 8 m 2 n 50 lr 0.05 0.263158 0.335012 0.301662 0.546159\n",
            " l 10 m 2 n 50 lr 0.05 0.263158 0.335012 0.301662 0.546159\n",
            "  l 8 m 2 n 20 lr 0.05 0.273684 0.329880 0.300790 0.529785\n",
            " l 10 m 2 n 20 lr 0.05 0.273684 0.329880 0.300790 0.529785\n",
            "  l 5 m 2 n 20 lr 0.05 0.273684 0.329880 0.300790 0.529785\n",
            "  l 10 m 2 n 20 lr 0.1 0.263158 0.334098 0.300189 0.546159\n",
            "   l 5 m 2 n 20 lr 0.1 0.263158 0.334098 0.300189 0.546159\n",
            "   l 8 m 2 n 20 lr 0.1 0.263158 0.334098 0.300189 0.546159\n",
            " l 10 m 2 n 100 lr 0.1 0.257895 0.328129 0.298819 0.549287\n",
            "  l 8 m 2 n 100 lr 0.1 0.257895 0.328129 0.298819 0.549287\n",
            "  l 5 m 2 n 100 lr 0.1 0.257895 0.328129 0.298819 0.549287\n",
            "  l 5 m 3 n 100 lr 0.1 0.268421 0.323950 0.298286 0.520715\n",
            "  l 5 m 3 n 20 lr 0.01 0.263158 0.323410 0.297124 0.532515\n",
            "   l 8 m 3 n 50 lr 0.1 0.263158 0.329866 0.296290 0.529628\n",
            "  l 10 m 3 n 50 lr 0.1 0.263158 0.329866 0.296290 0.529628\n",
            "  l 8 m 3 n 50 lr 0.05 0.263158 0.329602 0.295147 0.540852\n",
            " l 10 m 3 n 50 lr 0.05 0.263158 0.329602 0.295147 0.540852\n",
            "   l 8 m 5 n 20 lr 0.1 0.257895 0.323805 0.293568 0.549290\n",
            "  l 10 m 5 n 20 lr 0.1 0.263158 0.321581 0.293524 0.504618\n",
            "  l 8 m 5 n 20 lr 0.01 0.257895 0.323082 0.293034 0.539683\n",
            "  l 5 m 5 n 50 lr 0.05 0.257895 0.332125 0.292965 0.527884\n",
            "  l 5 m 5 n 50 lr 0.01 0.268421 0.322314 0.292062 0.499768\n",
            " l 5 m 3 n 100 lr 0.01 0.257895 0.330629 0.291620 0.511612\n",
            "  l 5 m 5 n 20 lr 0.01 0.257895 0.321526 0.291402 0.519944\n",
            "  l 8 m 3 n 50 lr 0.01 0.263158 0.327653 0.290937 0.519505\n",
            " l 10 m 3 n 50 lr 0.01 0.263158 0.327653 0.290937 0.519505\n",
            "   l 5 m 5 n 20 lr 0.1 0.257895 0.329473 0.290083 0.504825\n",
            "  l 8 m 5 n 50 lr 0.01 0.252632 0.327557 0.290041 0.548454\n",
            " l 5 m 5 n 100 lr 0.01 0.247368 0.331373 0.289967 0.548454\n",
            "  l 10 m 3 n 20 lr 0.1 0.257895 0.322841 0.289547 0.534492\n",
            "   l 8 m 3 n 20 lr 0.1 0.257895 0.322841 0.289547 0.534492\n",
            " l 5 m 3 n 100 lr 0.05 0.257895 0.328113 0.288039 0.495094\n",
            " l 10 m 5 n 50 lr 0.05 0.257895 0.318274 0.287921 0.495990\n",
            " l 8 m 3 n 100 lr 0.05 0.257895 0.325687 0.286376 0.498117\n",
            "l 10 m 3 n 100 lr 0.05 0.257895 0.325687 0.286376 0.498117\n",
            " l 5 m 5 n 100 lr 0.05 0.247368 0.330949 0.286268 0.526670\n",
            " l 10 m 5 n 50 lr 0.01 0.247368 0.325157 0.286076 0.546199\n",
            "  l 5 m 2 n 50 lr 0.01 0.252632 0.328627 0.285857 0.522865\n",
            "  l 8 m 2 n 50 lr 0.01 0.252632 0.328627 0.285857 0.522865\n",
            " l 10 m 2 n 50 lr 0.01 0.252632 0.328627 0.285857 0.522865\n",
            "   l 5 m 3 n 20 lr 0.1 0.252632 0.327007 0.285791 0.502778\n",
            "  l 8 m 5 n 20 lr 0.05 0.236842 0.328887 0.285548 0.579407\n",
            " l 10 m 3 n 20 lr 0.05 0.252632 0.324848 0.284983 0.518983\n",
            "  l 8 m 3 n 20 lr 0.05 0.252632 0.324848 0.284983 0.518983\n",
            "  l 5 m 3 n 50 lr 0.05 0.242105 0.330337 0.284490 0.540457\n",
            "  l 5 m 3 n 50 lr 0.01 0.252632 0.320479 0.284478 0.494505\n",
            " l 10 m 5 n 20 lr 0.05 0.247368 0.320761 0.284362 0.527193\n",
            " l 8 m 5 n 100 lr 0.05 0.247368 0.318841 0.284115 0.524259\n",
            "l 10 m 5 n 100 lr 0.05 0.252632 0.319866 0.284049 0.500251\n",
            "l 10 m 3 n 100 lr 0.01 0.252632 0.330100 0.283707 0.518774\n",
            " l 8 m 3 n 100 lr 0.01 0.252632 0.330100 0.283707 0.518774\n",
            "  l 5 m 5 n 100 lr 0.1 0.252632 0.318766 0.283231 0.489620\n",
            "  l 5 m 5 n 20 lr 0.05 0.252632 0.328137 0.283184 0.512972\n",
            "  l 5 m 3 n 20 lr 0.05 0.252632 0.328137 0.283184 0.512972\n",
            "  l 8 m 3 n 20 lr 0.01 0.252632 0.322163 0.283128 0.523037\n",
            " l 10 m 3 n 20 lr 0.01 0.252632 0.322163 0.283128 0.523037\n",
            "  l 10 m 5 n 50 lr 0.1 0.257895 0.320912 0.282264 0.492565\n",
            " l 8 m 5 n 100 lr 0.01 0.247368 0.327033 0.282152 0.523415\n",
            "   l 5 m 5 n 50 lr 0.1 0.247368 0.325268 0.281483 0.490306\n",
            "l 10 m 2 n 100 lr 0.01 0.242105 0.330663 0.280574 0.504558\n",
            " l 5 m 2 n 100 lr 0.01 0.242105 0.330663 0.280574 0.504558\n",
            " l 8 m 2 n 100 lr 0.01 0.242105 0.330663 0.280574 0.504558\n",
            "  l 8 m 5 n 50 lr 0.05 0.247368 0.330725 0.280480 0.526525\n",
            "   l 5 m 3 n 50 lr 0.1 0.247368 0.328630 0.277432 0.483817\n",
            " l 10 m 3 n 100 lr 0.1 0.242105 0.317023 0.275587 0.484604\n",
            "  l 8 m 3 n 100 lr 0.1 0.242105 0.317023 0.275587 0.484604\n",
            "   l 8 m 5 n 50 lr 0.1 0.242105 0.314344 0.274092 0.482766\n",
            "l 10 m 5 n 100 lr 0.01 0.236842 0.325805 0.274075 0.520468\n",
            "  l 8 m 5 n 100 lr 0.1 0.236842 0.311142 0.269820 0.496008\n",
            " l 10 m 5 n 100 lr 0.1 0.231579 0.318997 0.261966 0.487352\n",
            " l 10 m 2 n 20 lr 0.01 0.247368 0.300165 0.242963 0.358240\n",
            "  l 8 m 2 n 20 lr 0.01 0.247368 0.300165 0.242963 0.358240\n",
            "  l 5 m 2 n 20 lr 0.01 0.247368 0.300165 0.242963 0.358240\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "En este caso hemos obtenido un modelo mejor que el BM25 + LambdaMART y superior a BM25 en la métrica nDCG@10."
      ],
      "metadata": {
        "id": "i0QmYzCOsnE4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para usar otros métodos de learning to rank vamos a usar la colección de modelos de sklearn y otros predictores como baseline."
      ],
      "metadata": {
        "id": "lxh0WytdqlqX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.svm import SVR\n",
        "\n",
        "#RandomForest\n",
        "fsr = pt.FeaturesBatchRetrieve(index, controls = {'wmodel': 'BM25'}, features=['SAMPLE', 'WMODEL:DirichletLM', 'WMODEL:PL2'])\n",
        "rf = RandomForestRegressor(n_estimators=200)\n",
        "rf_pipe = fsr >> pt.ltr.apply_learned_model(rf)\n",
        "rf_pipe.fit(train, qrels, validation, qrels)\n",
        "\n",
        "#SVM kernel gaussiano\n",
        "fsr = pt.FeaturesBatchRetrieve(index, controls = {'wmodel': 'BM25'}, features=['SAMPLE', 'WMODEL:DirichletLM', 'WMODEL:PL2'])\n",
        "svr_rbf = SVR(kernel=\"rbf\", gamma=0.1, epsilon=0.1)\n",
        "rbf_pipe = fsr >> pt.ltr.apply_learned_model(svr_rbf)\n",
        "rbf_pipe.fit(train, qrels, validation, qrels)\n",
        "\n",
        "#SVM kernel lineal\n",
        "fsr = pt.FeaturesBatchRetrieve(index, controls = {'wmodel': 'BM25'}, features=['SAMPLE', 'WMODEL:DirichletLM', 'WMODEL:PL2'])\n",
        "svr_lin = SVR(kernel=\"linear\", gamma=\"auto\")\n",
        "lin_pipe = fsr >> pt.ltr.apply_learned_model(svr_lin)\n",
        "lin_pipe.fit(train, qrels, validation, qrels)\n",
        "\n",
        "\n",
        "eval(['BM25','BM25 + LambdaMART' ,'BM25 + Random Forest', 'BM25 + SVR rbf', 'BM25 + SVR lin'],\n",
        "     [bm25%50, ltr%50, rf_pipe%50, rbf_pipe%50, lin_pipe%50],\n",
        "     test, qrels, [P@10, nDCG, nDCG@10, RR], sort=nDCG@10, baseline=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJ1-f1PHsODJ",
        "outputId": "5cad81a6-883a-4965-c695-734243a04a1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                name       RR     P@10     nDCG  nDCG@10  RR +  RR -  RR p-value  P@10 +  P@10 -  P@10 p-value  nDCG +  nDCG -  nDCG p-value  nDCG@10 +  nDCG@10 -  nDCG@10 p-value\n",
            "                BM25 0.595052 0.252632 0.347720 0.306262   NaN   NaN         NaN     NaN     NaN           NaN     NaN     NaN           NaN        NaN        NaN              NaN\n",
            "      BM25 + SVR lin 0.593235 0.247368 0.339905 0.303418   2.0   2.0    0.519599     0.0     1.0      0.330565     5.0    11.0      0.070252        6.0        4.0         0.437400\n",
            "   BM25 + LambdaMART 0.548089 0.263158 0.328672 0.297730   4.0   5.0    0.407554     5.0     2.0      0.541631     5.0    12.0      0.063186        8.0        7.0         0.631685\n",
            "BM25 + Random Forest 0.444523 0.205263 0.254686 0.241619   3.0   8.0    0.067365     5.0     8.0      0.119603     3.0    15.0      0.001426        5.0       10.0         0.093339\n",
            "      BM25 + SVR rbf 0.434068 0.173684 0.167361 0.211559   5.0   6.0    0.062023     2.0     9.0      0.011797     1.0    17.0      0.000044        5.0        8.0         0.011358\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Probamos con BB2\n",
        "\n",
        "#RandomForest\n",
        "fsr = pt.FeaturesBatchRetrieve(index, controls = {'wmodel': 'BB2'}, features=['SAMPLE', 'WMODEL:BM25' , 'WMODEL:DirichletLM', 'WMODEL:PL2'])\n",
        "rf = RandomForestRegressor(n_estimators=200)\n",
        "rf_pipe = fsr >> pt.ltr.apply_learned_model(rf)\n",
        "rf_pipe.fit(train, qrels, validation, qrels)\n",
        "\n",
        "#SVM kernel gaussiano\n",
        "fsr = pt.FeaturesBatchRetrieve(index, controls = {'wmodel': 'BB2'}, features=['SAMPLE', 'WMODEL:BM25' , 'WMODEL:DirichletLM', 'WMODEL:PL2'])\n",
        "svr_rbf = SVR(kernel=\"rbf\", gamma=0.1, epsilon=0.1)\n",
        "rbf_pipe = fsr >> pt.ltr.apply_learned_model(svr_rbf)\n",
        "rbf_pipe.fit(train, qrels, validation, qrels)\n",
        "\n",
        "#SVM kernel lineal\n",
        "fsr = pt.FeaturesBatchRetrieve(index, controls = {'wmodel': 'BB2'}, features=['SAMPLE', 'WMODEL:BM25' , 'WMODEL:DirichletLM', 'WMODEL:PL2'])\n",
        "svr_lin = SVR(kernel=\"linear\", gamma=\"auto\")\n",
        "lin_pipe = fsr >> pt.ltr.apply_learned_model(svr_lin)\n",
        "lin_pipe.fit(train, qrels, validation, qrels)\n",
        "\n",
        "\n",
        "eval(['BB2','BB2 + LambdaMART' ,'BB2 + Random Forest', 'BB2 + SVR rbf', 'BB2 + SVR lin'],\n",
        "     [bb2%50, ltr%50, rf_pipe%50, rbf_pipe%50, lin_pipe%50],\n",
        "     test, qrels, [P@10, nDCG, nDCG@10, RR], sort=nDCG@10, baseline=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X0Xyscx-kF9d",
        "outputId": "de663904-b7ef-4b0a-bc31-c4f033425e67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "               name       RR     P@10     nDCG  nDCG@10  RR +  RR -  RR p-value  P@10 +  P@10 -  P@10 p-value  nDCG +  nDCG -  nDCG p-value  nDCG@10 +  nDCG@10 -  nDCG@10 p-value\n",
            "                BB2 0.595052 0.252632 0.347720 0.306262   NaN   NaN         NaN     NaN     NaN           NaN     NaN     NaN           NaN        NaN        NaN              NaN\n",
            "   BB2 + LambdaMART 0.548089 0.263158 0.328672 0.297730   4.0   5.0    0.407554     5.0     2.0      0.541631     5.0    12.0      0.063186        8.0        7.0         0.631685\n",
            "      BB2 + SVR lin 0.465507 0.189474 0.265397 0.226269   4.0   7.0    0.161507     2.0     9.0      0.014002     5.0    13.0      0.010527        4.0       11.0         0.023514\n",
            "BB2 + Random Forest 0.364167 0.200000 0.241777 0.201543   3.0  11.0    0.044433     3.0     9.0      0.115986     3.0    14.0      0.002438        3.0       14.0         0.013263\n",
            "      BB2 + SVR rbf 0.452924 0.147368 0.157309 0.194610   3.0   8.0    0.106800     1.0    10.0      0.018892     2.0    17.0      0.000426        2.0       11.0         0.024732\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pasamos a añadir características funcionales sobre los documentos y las queries para tratar de aportar más datos a los modelos, en particular hacemos una función que elimina algunas palabras en las queries y añadimos una feature que devuelve el porcentaje de palabras de la query presentes en el documento y otra que calcula la longitud de la query. Para comprobar su rendimiento lo probamos con un modelo que implementa BM25 y un lambdaMART."
      ],
      "metadata": {
        "id": "tkqg3O4wpKuo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ejemplo de características funcionales custom.\n",
        "import re\n",
        "\n",
        "def getTerms(docid):\n",
        "  di = index.getDirectIndex()\n",
        "  doi = index.getDocumentIndex()\n",
        "  lex = index.getLexicon()\n",
        "  res = \"\"\n",
        "  #NB: postings will be null if the document is empty\n",
        "  for posting in di.getPostings(doi.getDocumentEntry(docid)):\n",
        "      termid = posting.getId()\n",
        "      lee = lex.getLexiconEntry(termid)\n",
        "      res += lee.getKey() + ' '\n",
        "  return res\n",
        "\n",
        "stops=set([\"and\", \"the\", \"of\", \"use\", \"in\", \"on\", \"by\"])\n",
        "def _remove_stops(q):\n",
        "    terms = q[\"query\"].split(\" \")\n",
        "    terms = [t for t in terms if not t in stops ]\n",
        "    return \" \".join(terms)\n",
        "\n",
        "def _features(row):\n",
        "  content = getTerms(row['docid'])\n",
        "  myq = row['query']\n",
        "  common = set(myq.split()) & set(content.split())\n",
        "  f1 = len(content)\n",
        "  if np.isnan(f1):\n",
        "    f1=0\n",
        "  f2 = len(re.findall(r\"[^\\W\\d_]+|\\d+\", content))\n",
        "  if np.isnan(f2):\n",
        "    f2=0\n",
        "  f3 = len(common)/len(set(myq.split()))\n",
        "  if np.isnan(f3):\n",
        "    f3=0\n",
        "  f4 = len(myq)\n",
        "  if np.isnan(f4):\n",
        "    f4=0\n",
        "  return np.array([f1, f2,f3, f4])\n",
        "\n",
        "\n",
        "extended_fsr = pt.apply.query(_remove_stops) >> bm25 >> pt.FeaturesBatchRetrieve(index, ['SAMPLE', 'WMODEL:DirichletLM', 'WMODEL:PL2']) ** pt.apply.doc_features(_features)\n",
        "extended_ltr = extended_fsr >> pt.ltr.apply_learned_model(lmart, form=\"ltr\")\n",
        "extended_ltr.fit(train, qrels, validation, qrels)\n",
        "printsearch('Extended BM25 + LambdaMART', extended_ltr%10, q)\n",
        "eval(['Extended BM25 + LambdaMART'], [extended_ltr%50], test, qrels, [P@10, nDCG, nDCG@10, RR], sort=nDCG@10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wfE7Q-CPqAXE",
        "outputId": "4bb8beae-0955-411c-8250-604afea7a4c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Extended BM25 + LambdaMART\n",
            "   score docno\n",
            "2.389805  1586\n",
            "2.101079 11429\n",
            "0.802714  3559\n",
            "0.759680  7875\n",
            "0.705736  5130\n",
            "0.682963  2290\n",
            "0.572797  9165\n",
            "0.501424  4307\n",
            "0.447563  5429\n",
            "0.379482  3374\n",
            "                      name     P@10     nDCG  nDCG@10       RR\n",
            "Extended BM25 + LambdaMART 0.268421 0.341857  0.31164 0.575856\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para acabar esta sección creamos varios modelos extendidos mediante las features y árboles lambdaMART con los mejores hiperparámetros que encotramos en la sección. A continuación, comparamos su rendimiento con los de la primera tabla del apartado."
      ],
      "metadata": {
        "id": "TC8qe0ygGpEk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import lightgbm as lgb\n",
        "\n",
        "# Definimos el vector de características, e indicamos la función de ranking para el primer filtro de candidatos \"first stage ranking\".\n",
        "\n",
        "# Vamos a usar el modelo GBDT LambdaMART implementado en LightGBM.\n",
        "# Configuramos el modelo.\n",
        "lmart = lgb.LGBMRanker(\n",
        "    task='train',\n",
        "    min_data_in_leaf=2,\n",
        "    max_depth=2,\n",
        "    num_leaves=100,\n",
        "    objective='lambdarank',\n",
        "    metric='ndcg',\n",
        "    importance_type='gain',\n",
        "    reg_lambda=0.01,\n",
        "    n_estimators=100,\n",
        "    learning_rate = 0.05,\n",
        "    verbose=-1,\n",
        "    random_state=0 # For reproducibility\n",
        "    )\n",
        "\n",
        "\n",
        "#Extendido basado en BM25 + LambdaMART\n",
        "extended_fsr = pt.apply.query(_remove_stops) >> bm25 >> pt.FeaturesBatchRetrieve(index, ['SAMPLE', 'WMODEL:DirichletLM', 'WMODEL:PL2', 'WMODEL:BB2']) ** pt.apply.doc_features(_features)\n",
        "extended_ltr = extended_fsr >> pt.ltr.apply_learned_model(lmart, form=\"ltr\")\n",
        "extended_ltr.fit(train, qrels, validation, qrels)\n",
        "\n",
        "#Extendido basado en BB2 + LambdaMART\n",
        "bb2 = pt.BatchRetrieve(index, wmodel='BB2')\n",
        "extended_fsr_2 = pt.apply.query(_remove_stops) >> bb2 >> pt.FeaturesBatchRetrieve(index, ['SAMPLE', 'WMODEL:DirichletLM', 'WMODEL:PL2', 'WMODEL:BM25']) ** pt.apply.doc_features(_features)\n",
        "extended_ltr_2 = extended_fsr_2 >> pt.ltr.apply_learned_model(lmart, form=\"ltr\")\n",
        "extended_ltr_2.fit(train, qrels, validation, qrels)\n",
        "\n",
        "# Evaluamos y comparamos.\n",
        "eval(['Modelo vectorial', 'BM25', 'Query likelihood Dirichlet', 'DFR Poisson Laplace', 'DFR DPH', 'Extendido BM25 + LambdaMART', 'Extendido BB2 + LambdaMART'],\n",
        "     [vsm%50, bm25%50, qld%50, pl2%50, dph%50, extended_ltr%50,extended_ltr_2%50],\n",
        "     test, qrels, [P@10, nDCG, nDCG@10, RR], sort=nDCG@10, baseline=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8cWgd-QQG5gx",
        "outputId": "19a76b66-5bc5-49d5-d997-242cc8227f57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                       name       RR     P@10     nDCG  nDCG@10  RR +  RR -  RR p-value  P@10 +  P@10 -  P@10 p-value  nDCG +  nDCG -  nDCG p-value  nDCG@10 +  nDCG@10 -  nDCG@10 p-value\n",
            " Extendido BB2 + LambdaMART 0.612711 0.268421 0.363847 0.318225   5.0   4.0    0.841426     5.0     2.0      0.214558    11.0     7.0      0.206751        7.0        7.0         0.398563\n",
            "Extendido BM25 + LambdaMART 0.524027 0.289474 0.325914 0.311056   6.0   4.0    0.393571    10.0     3.0      0.041861     8.0    10.0      0.171089        9.0        7.0         0.772009\n",
            "                       BM25 0.595052 0.252632 0.347720 0.306262   2.0   1.0    0.606020     1.0     0.0      0.330565     7.0     8.0      0.865871        3.0        4.0         0.569843\n",
            "           Modelo vectorial 0.596739 0.247368 0.347220 0.304047   NaN   NaN         NaN     NaN     NaN           NaN     NaN     NaN           NaN        NaN        NaN              NaN\n",
            "        DFR Poisson Laplace 0.568381 0.242105 0.329377 0.296378   3.0   2.0    0.299321     1.0     2.0      0.577753     5.0    12.0      0.011144        6.0        4.0         0.514222\n",
            "                    DFR DPH 0.558020 0.247368 0.325935 0.288743   4.0   3.0    0.527410     5.0     4.0      1.000000     7.0    10.0      0.131491        7.0        9.0         0.538287\n",
            " Query likelihood Dirichlet 0.348071 0.168421 0.205987 0.179280   4.0  11.0    0.048660     2.0    11.0      0.007139     4.0    14.0      0.001026        3.0       14.0         0.002702\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como podemos comprobar, los dos modelos nuevos son ligeramente mejores que el resto."
      ],
      "metadata": {
        "id": "mKJDLt5IJ8ax"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Opcional: dense retrieval."
      ],
      "metadata": {
        "id": "sFjHN7Yf0VDP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ejemplo: obtención y visualización de embeddings."
      ],
      "metadata": {
        "id": "qxXjzgCl6wQ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracción de embeddings y embeddings pre-entrenados.\n",
        "!pip install --upgrade --ignore-installed gensim\n",
        "import gensim\n",
        "from gensim import corpora\n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.models import Word2Vec\n",
        "from gensim.models import KeyedVectors\n",
        "import numpy as np\n",
        "\n",
        "# Embeddings para la colección de juguete del ejercicio 1 (reutilizando la variable \"texts\").\n",
        "words = [[word for word in simple_preprocess(text) if word not in stoplist] for text in texts]\n",
        "model = Word2Vec(words).wv\n",
        "\n",
        "!wget https://huggingface.co/LoganKilpatrick/GoogleNews-vectors-negative300/resolve/main/GoogleNews-vectors-negative300.bin.gz\n",
        "premodel = gensim.models.KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin.gz', binary=True)\n",
        "\n",
        "print(model.most_similar(['paradox'], topn=20))\n",
        "print(premodel.most_similar(['paradox'], topn=20))\n",
        "\n",
        "def reduce_dimensions(model):\n",
        "  from sklearn.decomposition import IncrementalPCA  # inital reduction\n",
        "  from sklearn.manifold import TSNE                 # final reduction\n",
        "  num_dimensions = 2                                # final num dimensions (2D, 3D, etc)\n",
        "  tsne = TSNE(n_components=num_dimensions, random_state=0)\n",
        "  vectors = tsne.fit_transform(np.asarray(model.vectors))\n",
        "  return [v[0] for v in vectors], [v[1] for v in vectors], np.asarray(model.index_to_key)\n",
        "\n",
        "def plot(x_vals, y_vals, labels):\n",
        "  import matplotlib.pyplot as plt\n",
        "  import random\n",
        "  plt.figure(figsize=(12, 12))\n",
        "  plt.scatter(x_vals, y_vals, facecolors='none', edgecolors='b', linewidth=.5, s=80, alpha=.5)\n",
        "  for i in random.sample(list(range(len(labels))), 25): plt.annotate(labels[i], (x_vals[i], y_vals[i]))\n",
        "\n",
        "plot(*reduce_dimensions(model))"
      ],
      "metadata": {
        "id": "V3mLV_XO0OVO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ejercicio: dense retrieval con embeddings.\n",
        "\n",
        "Definir una función de ránking no supervisado basada en embeddings. Utilizar las implementaciones de gensym y la colección de juguete del ejercicio 1, u otras opciones a elección del estudiante."
      ],
      "metadata": {
        "id": "ye1cLZ_j7FJv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "La idea que se nos ha ocurrido para utilizar los embeddings para realizar ránking es la de obtener la similitud entre la query de entrada con todos los documentos y ordenar estos resultados de mayor a menor. Tomamos el vector de embeddings de un documento y de una query como la media de los embeddings de cada palabra presente en el texto. Una vez obtenidos estos vectores, los comparamos usando la similitud del coseno. Tenemos dos colecciones de embeddings con los que trabajar: el general de Google y el generado por los propios textos.\n",
        "\n",
        "Presentamos el código de esta implementación:"
      ],
      "metadata": {
        "id": "0UEODgxwMFLW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Precalculamos el embedding medio de cada documento\n",
        "\n",
        "def get_mean_emb(text, embeding):\n",
        "  word_vecs = []\n",
        "  for word in simple_preprocess(text):\n",
        "    try:\n",
        "      v = embeding[word]\n",
        "      word_vecs.append(v)\n",
        "    except KeyError:\n",
        "      pass\n",
        "  return np.mean(word_vecs, axis=0)\n",
        "\n",
        "embeding_model = [get_mean_emb(text, model) for text in texts]\n",
        "embeding_premodel = [get_mean_emb(text, premodel) for text in texts]"
      ],
      "metadata": {
        "id": "QtUVoBsO5oOQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Definimos la funcion de ranking dado un embedding\n",
        "\n",
        "def rank_emb(query, embeding, mean_emb):\n",
        "  v_q = get_mean_emb(query, embeding)\n",
        "  result = []\n",
        "  for i in range(len(mean_emb)):\n",
        "    v_d = mean_emb[i]\n",
        "    csim = np.dot(v_q, v_d) / (np.linalg.norm(v_q) * np.linalg.norm(v_d))\n",
        "    if np.isnan(np.sum(csim)):\n",
        "      csim = 0\n",
        "    result.append((list(freqvector.keys())[i], csim))\n",
        "  result.sort(key=lambda x: x[1], reverse=True)\n",
        "  return result"
      ],
      "metadata": {
        "id": "kEqgOI13W9G4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Probamos tres consultas.\n",
        "for q in [['descartes', 'montesquieu'], ['thought', 'experiment', 'identity'], ['market', 'paradox']]:\n",
        "  print('\\n------------------------------')\n",
        "  print('Query:', q)\n",
        "  print('\\nEmbedding de los textos')\n",
        "  for url, score in rank_emb(\" \".join(q), model, embeding_model):\n",
        "    print(score, url)\n",
        "  print('\\nEmbedding de Google')\n",
        "  for url, score in rank_emb(\" \".join(q), premodel, embeding_premodel):\n",
        "    print(score, url)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SB_GzvE3Z9md",
        "outputId": "2ea6574d-3397-4e64-a2b0-b68779f08b4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "------------------------------\n",
            "Query: ['descartes', 'montesquieu']\n",
            "\n",
            "Embedding de los textos\n",
            "0.99974203 https://en.wikipedia.org/wiki/Condorcet_paradox\n",
            "0.9997304 https://en.wikipedia.org/wiki/Age_of_Enlightenment\n",
            "0.99972713 https://en.wikipedia.org/wiki/Friendship_paradox\n",
            "0.9997251 https://en.wikipedia.org/wiki/Paradox_of_value\n",
            "0.9997225 https://en.wikipedia.org/wiki/Simpson%27s_paradox\n",
            "0.99972093 https://en.wikipedia.org/wiki/French_Revolution\n",
            "0.99970716 https://en.wikipedia.org/wiki/Winner%27s_curse\n",
            "0.99970347 https://en.wikipedia.org/wiki/Rationalism\n",
            "0.9996895 https://en.wikipedia.org/wiki/Scientific_Revolution\n",
            "0.9996765 https://en.wikipedia.org/wiki/Ship_of_Theseus\n",
            "\n",
            "Embedding de Google\n",
            "0 https://en.wikipedia.org/wiki/Age_of_Enlightenment\n",
            "0 https://en.wikipedia.org/wiki/Rationalism\n",
            "0 https://en.wikipedia.org/wiki/Scientific_Revolution\n",
            "0 https://en.wikipedia.org/wiki/French_Revolution\n",
            "0 https://en.wikipedia.org/wiki/Winner%27s_curse\n",
            "0 https://en.wikipedia.org/wiki/Simpson%27s_paradox\n",
            "0 https://en.wikipedia.org/wiki/Friendship_paradox\n",
            "0 https://en.wikipedia.org/wiki/Condorcet_paradox\n",
            "0 https://en.wikipedia.org/wiki/Paradox_of_value\n",
            "0 https://en.wikipedia.org/wiki/Ship_of_Theseus\n",
            "\n",
            "------------------------------\n",
            "Query: ['thought', 'experiment', 'identity']\n",
            "\n",
            "Embedding de los textos\n",
            "0.9998309 https://en.wikipedia.org/wiki/Winner%27s_curse\n",
            "0.99982834 https://en.wikipedia.org/wiki/Age_of_Enlightenment\n",
            "0.9998251 https://en.wikipedia.org/wiki/Friendship_paradox\n",
            "0.9998209 https://en.wikipedia.org/wiki/Paradox_of_value\n",
            "0.9998197 https://en.wikipedia.org/wiki/French_Revolution\n",
            "0.999819 https://en.wikipedia.org/wiki/Condorcet_paradox\n",
            "0.9998185 https://en.wikipedia.org/wiki/Ship_of_Theseus\n",
            "0.9998172 https://en.wikipedia.org/wiki/Simpson%27s_paradox\n",
            "0.99980783 https://en.wikipedia.org/wiki/Rationalism\n",
            "0.99980426 https://en.wikipedia.org/wiki/Scientific_Revolution\n",
            "\n",
            "Embedding de Google\n",
            "0.52539253 https://en.wikipedia.org/wiki/Rationalism\n",
            "0.5055134 https://en.wikipedia.org/wiki/Ship_of_Theseus\n",
            "0.50373983 https://en.wikipedia.org/wiki/Scientific_Revolution\n",
            "0.4908213 https://en.wikipedia.org/wiki/Condorcet_paradox\n",
            "0.48569047 https://en.wikipedia.org/wiki/Friendship_paradox\n",
            "0.47640383 https://en.wikipedia.org/wiki/Age_of_Enlightenment\n",
            "0.4620036 https://en.wikipedia.org/wiki/Simpson%27s_paradox\n",
            "0.46075898 https://en.wikipedia.org/wiki/Winner%27s_curse\n",
            "0.4561549 https://en.wikipedia.org/wiki/Paradox_of_value\n",
            "0.4210163 https://en.wikipedia.org/wiki/French_Revolution\n",
            "\n",
            "------------------------------\n",
            "Query: ['market', 'paradox']\n",
            "\n",
            "Embedding de los textos\n",
            "0.99992096 https://en.wikipedia.org/wiki/Simpson%27s_paradox\n",
            "0.9999177 https://en.wikipedia.org/wiki/Condorcet_paradox\n",
            "0.99990153 https://en.wikipedia.org/wiki/Friendship_paradox\n",
            "0.99989945 https://en.wikipedia.org/wiki/Paradox_of_value\n",
            "0.99988306 https://en.wikipedia.org/wiki/Winner%27s_curse\n",
            "0.99986094 https://en.wikipedia.org/wiki/Ship_of_Theseus\n",
            "0.99985516 https://en.wikipedia.org/wiki/Rationalism\n",
            "0.99984497 https://en.wikipedia.org/wiki/Age_of_Enlightenment\n",
            "0.9998344 https://en.wikipedia.org/wiki/Scientific_Revolution\n",
            "0.9998163 https://en.wikipedia.org/wiki/French_Revolution\n",
            "\n",
            "Embedding de Google\n",
            "0.459083 https://en.wikipedia.org/wiki/Condorcet_paradox\n",
            "0.45344758 https://en.wikipedia.org/wiki/Winner%27s_curse\n",
            "0.4531027 https://en.wikipedia.org/wiki/Simpson%27s_paradox\n",
            "0.4528232 https://en.wikipedia.org/wiki/Paradox_of_value\n",
            "0.4447408 https://en.wikipedia.org/wiki/Rationalism\n",
            "0.4159271 https://en.wikipedia.org/wiki/Friendship_paradox\n",
            "0.4144395 https://en.wikipedia.org/wiki/Age_of_Enlightenment\n",
            "0.40122786 https://en.wikipedia.org/wiki/Scientific_Revolution\n",
            "0.37126383 https://en.wikipedia.org/wiki/Ship_of_Theseus\n",
            "0.36158988 https://en.wikipedia.org/wiki/French_Revolution\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Los resultados son coherentes con los embeddings utilizados: en el caso de los sacados de los propios textos las similitudes son cercanas a uno para todos los casos y en caso de usar los embedings de Google obtenemos similitudes más bajas. En el caso de la primera query obtenemos similitudes de cero ya que el embeding no contiene los nombres propios presentes en la consulta."
      ],
      "metadata": {
        "id": "GQXy0a_0cemt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Opcional: deep learning to rank.\n",
        "\n",
        "Aplicar un modelo de deep learning sobre alguno de los conjuntos de datos de los ejercicios anteriores. Por ejemplo, utilizar alguno de los modelos disponibles en PyTerrier."
      ],
      "metadata": {
        "id": "CXTp_VlGz7Tf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Usamos la implementación de sklearn de redes neuronales y la aplicamos a un pipeline de PyTerrier con los datos del ejercicio 2."
      ],
      "metadata": {
        "id": "eX1ma74cdg_n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPRegressor\n",
        "\n",
        "#Modelo simple 1 capa oculta de 100 neuronas con BM25\n",
        "\n",
        "regr = MLPRegressor(random_state=1, max_iter=500)\n",
        "pipenn1_100 = pt.apply.query(_remove_stops) >> bm25 >> pt.FeaturesBatchRetrieve(index, ['SAMPLE', 'WMODEL:DirichletLM', 'WMODEL:PL2']) ** pt.apply.doc_features(_features)\n",
        "pipenn1_100 = pipenn1_100 >> pt.ltr.apply_learned_model(regr)\n",
        "pipenn1_100.fit(train, qrels, validation, qrels)\n",
        "\n",
        "#Modelo simple 1 capa oculta de 100 neuronas con BB2\n",
        "regr = MLPRegressor(random_state=1, max_iter=500)\n",
        "pipenn2_100 = pt.apply.query(_remove_stops) >> bb2 >> pt.FeaturesBatchRetrieve(index, ['SAMPLE', 'WMODEL:DirichletLM', 'WMODEL:PL2']) ** pt.apply.doc_features(_features)\n",
        "pipenn2_100 = pipenn2_100 >> pt.ltr.apply_learned_model(regr)\n",
        "pipenn2_100.fit(train, qrels, validation, qrels)"
      ],
      "metadata": {
        "id": "4m-V0bnWguU6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Modelo con capas ocultas de 120,130,200,100 neuronas con BM25\n",
        "\n",
        "regr = MLPRegressor(hidden_layer_sizes = [120, 130, 200, 100],random_state=1, max_iter=500)\n",
        "pipenn1_200 = pt.apply.query(_remove_stops) >> bm25 >> pt.FeaturesBatchRetrieve(index, ['SAMPLE', 'WMODEL:DirichletLM', 'WMODEL:PL2']) ** pt.apply.doc_features(_features)\n",
        "pipenn1_200 = pipenn1_200 >> pt.ltr.apply_learned_model(regr)\n",
        "pipenn1_200.fit(train, qrels, validation, qrels)\n",
        "\n",
        "#Modelo con capas ocultas de 120,130,200,100 neuronas con BB2\n",
        "regr = MLPRegressor(hidden_layer_sizes = [120, 130, 200, 100], random_state=1, max_iter=500)\n",
        "pipenn2_200 = pt.apply.query(_remove_stops) >> bb2 >> pt.FeaturesBatchRetrieve(index, ['SAMPLE', 'WMODEL:DirichletLM', 'WMODEL:PL2']) ** pt.apply.doc_features(_features)\n",
        "pipenn2_200 = pipenn2_200 >> pt.ltr.apply_learned_model(regr)\n",
        "pipenn2_200.fit(train, qrels, validation, qrels)\n"
      ],
      "metadata": {
        "id": "G1I_KJeWig_6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluamos y comparamos.\n",
        "eval(['Modelo vectorial', 'BM25', 'Query likelihood Dirichlet', 'DFR Poisson Laplace', 'DFR DPH',\n",
        "       'Simple NN + BM25', 'Simple NN + BB2', 'Complex NN + BM25', 'Complex NN + BB2'],\n",
        "     [vsm%50, bm25%50, qld%50, pl2%50, dph%50, pipenn1_100%50, pipenn2_100%50,pipenn1_200%50,pipenn2_200%50],\n",
        "     test, qrels, [P@10, nDCG, nDCG@10, RR], sort=nDCG@10, baseline=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kixldrIFjieu",
        "outputId": "7a8a9636-1b28-45b4-c69f-d3a2f168a673"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                      name       RR     P@10     nDCG  nDCG@10  RR +  RR -  RR p-value  P@10 +  P@10 -  P@10 p-value  nDCG +  nDCG -  nDCG p-value  nDCG@10 +  nDCG@10 -  nDCG@10 p-value\n",
            "                      BM25 0.595052 0.252632 0.347720 0.306262   2.0   1.0    0.606020     1.0     0.0      0.330565     7.0     8.0      0.865871        3.0        4.0         0.569843\n",
            "          Modelo vectorial 0.596739 0.247368 0.347220 0.304047   NaN   NaN         NaN     NaN     NaN           NaN     NaN     NaN           NaN        NaN        NaN              NaN\n",
            "       DFR Poisson Laplace 0.568381 0.242105 0.329377 0.296378   3.0   2.0    0.299321     1.0     2.0      0.577753     5.0    12.0      0.011144        6.0        4.0         0.514222\n",
            "                   DFR DPH 0.558020 0.247368 0.325935 0.288743   4.0   3.0    0.527410     5.0     4.0      1.000000     7.0    10.0      0.131491        7.0        9.0         0.538287\n",
            "          Complex NN + BB2 0.516455 0.242105 0.310922 0.284684   6.0   5.0    0.399468     4.0     4.0      0.841269     7.0    10.0      0.088907        9.0        8.0         0.463886\n",
            "         Complex NN + BM25 0.516079 0.236842 0.264705 0.269401   7.0   4.0    0.253767     2.0     3.0      0.606520     4.0    15.0      0.007452        5.0       11.0         0.196115\n",
            "          Simple NN + BM25 0.475063 0.226316 0.278601 0.260095   2.0   9.0    0.046657     1.0     5.0      0.103643     3.0    14.0      0.001351        4.0       11.0         0.025885\n",
            "           Simple NN + BB2 0.446154 0.215789 0.239843 0.245085   2.0   9.0    0.020232     2.0     6.0      0.110524     4.0    13.0      0.000691        4.0       11.0         0.019483\n",
            "Query likelihood Dirichlet 0.348071 0.168421 0.205987 0.179280   4.0  11.0    0.048660     2.0    11.0      0.007139     4.0    14.0      0.001026        3.0       14.0         0.002702\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Los resultados no son malos pero no superan  a los modelos de tipo lambdaMART."
      ],
      "metadata": {
        "id": "ZyZoYNqipThp"
      }
    }
  ]
}